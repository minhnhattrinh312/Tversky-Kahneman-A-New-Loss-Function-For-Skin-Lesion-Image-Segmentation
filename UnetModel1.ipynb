{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"UnetModel1.ipynb","provenance":[{"file_id":"1OZIK_qbOCMvdqoAlDBHh3ZR-VU5dqVzk","timestamp":1625401595405}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"WUKL5tItlFNe"},"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras import models,layers\n","from tensorflow.keras.utils import get_file\n","from tensorflow.keras.models import *\n","from tensorflow.keras.layers import *\n","import re\n","from collections import namedtuple\n","import tensorflow.keras.backend as K\n","import math"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sj94f86zIBAe"},"source":["## Vanila"]},{"cell_type":"code","metadata":{"id":"mf_yTvghlWPc"},"source":["def mvn(tensor):\n","    '''Performs per-channel spatial mean-variance normalization.'''\n","    epsilon = 1e-6\n","    mean = K.mean(tensor, axis=(1,2), keepdims=True)\n","    std = K.std(tensor, axis=(1,2), keepdims=True)\n","    mvn = (tensor - mean) / (std + epsilon)\n","    \n","    return mvn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NGsJHqIorCsT"},"source":["def up_and_concate(down_layer, layer, data_format='channels_last'):\n","    data_format='channels_last'\n","    if data_format == 'channels_first':\n","        in_channel = down_layer.get_shape().as_list()[1]\n","    else:\n","        in_channel = down_layer.get_shape().as_list()[3]\n","\n","    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n","    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n","\n","    if data_format == 'channels_first':\n","        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n","    else:\n","        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n","\n","    concate = my_concat([up, layer])\n","\n","    return concate\n","def attention_up_and_concate(down_layer, layer, data_format='channels_last'):\n","    data_format='channels_last'\n","    if data_format == 'channels_first':\n","        in_channel = down_layer.get_shape().as_list()[1]\n","    else:\n","        in_channel = down_layer.get_shape().as_list()[3]\n","\n","    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n","    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n","\n","    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4, data_format=data_format)\n","\n","    if data_format == 'channels_first':\n","        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n","    else:\n","        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n","\n","    concate = my_concat([up, layer])\n","    return concate\n","def attention_block_2d(x, g, inter_channel, data_format='channels_last'):\n","    data_format='channels_last'\n","    # theta_x(?,g_height,g_width,inter_channel)\n","\n","    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(x)\n","\n","    # phi_g(?,g_height,g_width,inter_channel)\n","\n","    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(g)\n","\n","    # f(?,g_height,g_width,inter_channel)\n","\n","    f = Activation('relu')(add([theta_x, phi_g]))\n","\n","    # psi_f(?,g_height,g_width,1)\n","\n","    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format=data_format)(f)\n","\n","    rate = Activation('sigmoid')(psi_f)\n","\n","    # rate(?,x_height,x_width)\n","\n","    # att_x(?,x_height,x_width,x_channel)\n","\n","    att_x = multiply([x, rate])\n","\n","    return att_x\n","def res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n","\n","              padding='same', data_format='channels_first'):\n","    data_format='channels_last'\n","    if data_format == 'channels_first':\n","        input_n_filters = input_layer.get_shape().as_list()[1]\n","    else:\n","        input_n_filters = input_layer.get_shape().as_list()[3]\n","\n","    layer = input_layer\n","    for i in range(2):\n","        layer = Conv2D(out_n_filters // 4, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n","        if batch_normalization:\n","            layer = BatchNormalization()(layer)\n","        layer = Activation('relu')(layer)\n","        layer = Conv2D(out_n_filters // 4, kernel_size, strides=stride, padding=padding, data_format=data_format)(layer)\n","        layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n","\n","    if out_n_filters != input_n_filters:\n","        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n","            input_layer)\n","    else:\n","        skip_layer = input_layer\n","    out_layer = add([layer, skip_layer])\n","    return out_layer\n","\n","\n","# Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\n","def rec_res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n","\n","                  padding='same', data_format='channels_first'):\n","    data_format='channels_last'\n","    if data_format == 'channels_first':\n","        input_n_filters = input_layer.get_shape().as_list()[1]\n","    else:\n","        input_n_filters = input_layer.get_shape().as_list()[3]\n","\n","    if out_n_filters != input_n_filters:\n","        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n","            input_layer)\n","    else:\n","        skip_layer = input_layer\n","\n","    layer = skip_layer\n","    for j in range(2):\n","\n","        for i in range(2):\n","            if i == 0:\n","\n","                layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n","                    layer)\n","                if batch_normalization:\n","                    layer1 = BatchNormalization()(layer1)\n","                layer1 = Activation('relu')(layer1)\n","            layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n","                add([layer1, layer]))\n","            if batch_normalization:\n","                layer1 = BatchNormalization()(layer1)\n","            layer1 = Activation('relu')(layer1)\n","        layer = layer1\n","\n","    out_layer = add([layer, skip_layer])\n","    return out_layer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTdVEyPxbjcH"},"source":["import keras.backend as K\n","class Swish(tf.keras.layers.Layer):\n","    def __init__(self, name=None, **kwargs):\n","        super().__init__(name=name, **kwargs)\n","\n","    def call(self, inputs, **kwargs):\n","        return tf.nn.swish(inputs)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config['name'] = self.name\n","        return config\n","def squeeze_excite_block(reduce_ratio=0.25,name_block=None):\n","  def call(inputs):\n","    filters = inputs.shape[-1]\n","    num_reduced_filters= max(1, int(filters * reduce_ratio))\n","    se = Lambda(lambda a: K.mean(a, axis=[1,2], keepdims=True))(inputs)\n","\n","    se = Conv2D(\n","            num_reduced_filters,\n","            kernel_size=[1, 1],\n","            strides=[1, 1],\n","            kernel_initializer='he_normal',\n","            padding='same',\n","            use_bias=True\n","        )(se)\n","    se = ReLU()(se) ############Swish()(se)\n","    se = Conv2D(\n","            filters,\n","            kernel_size=[1, 1],\n","            strides=[1, 1],\n","            kernel_initializer='he_normal',\n","            padding='same',\n","            use_bias=True\n","        )(se)\n","    se = Activation('sigmoid')(se)\n","    if name_block is not None:\n","      out = Multiply(name=name_block)([se, inputs])\n","    else : \n","      out = Multiply()([se, inputs])\n","    return out\n","  return call\n","\n","def conv_block(filters,kernel_size = (3,3), dilation = 1,block_name=None):\n","  def call(inputs):\n","    x = inputs\n","\n","    x = Conv2D(filters, kernel_size, padding=\"same\",dilation_rate =dilation ,use_bias=False,kernel_initializer='he_normal')(x)\n","    x = BatchNormalization()(x)\n","    x = Swish()(x)\n","\n","    x = Conv2D(filters, kernel_size, padding=\"same\",dilation_rate =dilation, use_bias=False,kernel_initializer='he_normal')(x)\n","    x = BatchNormalization()(x)\n","    x = Swish()(x)\n","\n","    x = squeeze_excite_block(name_block=block_name)(x)\n","\n","    return x\n","  return call\n","\n","\n","def decoder_block(n_filter,skip=None):\n","  def call(inputs):\n","    x= Conv2DTranspose(n_filter, (2,2), strides=(2, 2), padding='same',kernel_initializer = 'he_normal')(inputs)\n","    out = x\n","    if skip is not None :\n","      attention = conv_block(n_filter)(skip)\n","      out = Concatenate()([x,attention])\n","    out = conv_block(n_filter)(out)\n","\n","    return out\n","  return call\n","def dow_block(kernel_size=(2,2),stride=(2,2)):\n","  def call(inputs):\n","    out = MaxPooling2D(kernel_size, strides=stride)(inputs)\n","    return out\n","  return call\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fdnq2TWoejq-"},"source":["def encoderSegnet(input_s=(128,128,1)):\n","  down_block = dow_block()\n","  inp= Input(shape=input_s)\n","  o = inp\n","  nums_filter=[64,128,256,512,512]\n","  count=0\n","  for f in nums_filter[:-1]:\n","    count+=1\n","    o = conv_block(f,block_name='output_block_'+str(count))(o)\n","    o = down_block(o)\n","\n","  o = conv_block(nums_filter[-1],block_name='output_block_'+str(count+1))(o)\n","  #o = Dropout(0.5)(o)\n","  return Model(inp,o)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l2eYxd5bhNuG"},"source":["list_skip = [\"output_block_4\", \"output_block_3\", \"output_block_2\", \"output_block_1\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KE7RQQ227g4N"},"source":["def ASPP(x, filter):\n","    shape = x.shape\n","\n","    y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(x)\n","    y1 = Conv2D(filter, 1, padding=\"same\",use_bias=False,kernel_initializer='he_normal')(y1)\n","    #y1 = BatchNormalization()(y1)\n","    y1 = Lambda(mvn)(y1)\n","    y1 = ReLU()(y1)\n","    y1 = UpSampling2D((shape[1], shape[2]), interpolation='bilinear')(y1)\n","    #y1 = squeeze_excite_block()(y1)\n","\n","    y2 = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    #y2 = BatchNormalization()(y2)\n","    y2 = Lambda(mvn)(y2)\n","    y2 = ReLU()(y2)\n","    #y2 = squeeze_excite_block()(y2)\n","\n","    y3 = Conv2D(filter, 3, dilation_rate=6, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    #y3 = BatchNormalization()(y3)\n","    y3 = Lambda(mvn)(y3)\n","    y3 = ReLU()(y3)\n","    #y3 = squeeze_excite_block()(y3)\n","\n","    y4 = Conv2D(filter, 5, dilation_rate=12, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    #y4 = BatchNormalization()(y4)\n","    y4 = Lambda(mvn)(y4)\n","    y4 = ReLU()(y4)\n","    #y4 = squeeze_excite_block()(y4)\n","\n","    y5 = Conv2D(filter, 7, dilation_rate=18, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    #y5 = BatchNormalization()(y5)\n","    y5 = Lambda(mvn)(y5)\n","    y5 = ReLU()(y5)\n","    #y5 = squeeze_excite_block()(y5)\n","\n","    y = Concatenate()([y1, y2, y3, y4, y5])\n","\n","    y = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(y)\n","    #y = BatchNormalization()(y)\n","    y = Lambda(mvn)(y)\n","    y = ReLU()(y)\n","    #y = squeeze_excite_block()(y)\n","    return y\n","\n","def ASPP1(x, filter):\n","    shape = x.shape\n","\n","    y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(x)\n","    y1 = Conv2D(filter, 1, padding=\"same\",use_bias=False,kernel_initializer='he_normal')(y1)\n","    y1 = BatchNormalization()(y1)\n","    #y1 = Lambda(mvn)(y1)\n","    y1 = Swish()(y1)\n","    y1 = UpSampling2D((shape[1], shape[2]), interpolation='bilinear')(y1)\n","    y1 = squeeze_excite_block()(y1)\n","\n","    y2 = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y2 = BatchNormalization()(y2)\n","    #y2 = Lambda(mvn)(y2)\n","    y2 = Swish()(y2)\n","    y2 = squeeze_excite_block()(y2)\n","\n","    y3 = Conv2D(filter, 3, dilation_rate=6, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y3 = BatchNormalization()(y3)\n","    #y3 = Lambda(mvn)(y3)\n","    y3 = Swish()(y3)\n","    y3 = squeeze_excite_block()(y3)\n","\n","    y4 = Conv2D(filter, 5, dilation_rate=12, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y4 = BatchNormalization()(y4)\n","    #y4 = Lambda(mvn)(y4)\n","    y4 = Swish()(y4)\n","    y4 = squeeze_excite_block()(y4)\n","\n","    y5 = Conv2D(filter, 7, dilation_rate=18, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    y5 = BatchNormalization()(y5)\n","    #y5 = Lambda(mvn)(y5)\n","    y5 = Swish()(y5)\n","    y5 = squeeze_excite_block()(y5)\n","\n","    y = Concatenate()([y1, y2, y3, y4, y5])\n","\n","    y = Conv2D(filter, 1, dilation_rate=1, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(y)\n","    y = BatchNormalization()(y)\n","    #y = Lambda(mvn)(y)\n","    y = Swish()(y)\n","    y = squeeze_excite_block()(y)\n","    return y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9MmIu2lug_lf"},"source":["def seg_net(input_shape= (192,288,2), list_skip = list_skip,out_channels=3):\n","  encoder = encoderSegnet(input_s = input_shape)\n","  skip_connect=[encoder.get_layer(i).output for i in list_skip]\n","  num_filters = [512,256, 128, 64]\n","\n","  o = encoder.output\n","  o = ASPP1(o,128)\n","  \n","  for i, f in enumerate(num_filters):\n","    o = decoder_block(f,skip=skip_connect[i])(o)\n","  \n","  o = Conv2D(out_channels,(3, 3), padding='same', kernel_initializer='he_normal')(o)\n","  # yn = Activation('softmax')(o[...,:-1])\n","  # bn = o[...,-1:]\n","  # output = Concatenate()([yn,bn])\n","  if out_channels > 1 : \n","    output = Activation('softmax', name = 'softmax')(o)\n","  else :\n","    output = Activation('sigmoid', name = 'sigmoid')(o)\n","  return Model(encoder.input,output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6YLGKGB6ld3x"},"source":["#generator = seg_net(input_shape = (192,256,3), out_channels=2)\n","#generator.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7BhPhF64dpKc"},"source":["## EfficientUnet"]},{"cell_type":"code","metadata":{"id":"8RoZfTO_b_VG"},"source":["GlobalParams = namedtuple('GlobalParams', ['batch_norm_momentum', 'batch_norm_epsilon', 'dropout_rate', 'num_classes',\n","                                           'width_coefficient', 'depth_coefficient', 'depth_divisor', 'min_depth',\n","                                           'drop_connect_rate'])\n","GlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)\n","\n","BlockArgs = namedtuple('BlockArgs', ['kernel_size', 'num_repeat', 'input_filters', 'output_filters', 'expand_ratio',\n","                                     'id_skip', 'strides', 'se_ratio'])\n","BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n","\n","IMAGENET_WEIGHTS = {\n","\n","    'efficientnet-b0': {\n","        'name': 'efficientnet-b0_imagenet_1000.h5',\n","        'url': 'https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000.h5',\n","        'md5': 'bca04d16b1b8a7c607b1152fe9261af7',\n","    },\n","\n","    'efficientnet-b1': {\n","        'name': 'efficientnet-b1_imagenet_1000.h5',\n","        'url': 'https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b1_imagenet_1000.h5',\n","        'md5': 'bd4a2b82f6f6bada74fc754553c464fc',\n","    },\n","\n","    'efficientnet-b2': {\n","        'name': 'efficientnet-b2_imagenet_1000.h5',\n","        'url': 'https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b2_imagenet_1000.h5',\n","        'md5': '45b28b26f15958bac270ab527a376999',\n","    },\n","\n","    'efficientnet-b3': {\n","        'name': 'efficientnet-b3_imagenet_1000.h5',\n","        'url': 'https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b3_imagenet_1000.h5',\n","        'md5': 'decd2c8a23971734f9d3f6b4053bf424',\n","    },\n","\n","    'efficientnet-b4': {\n","        'name': 'efficientnet-b4_imagenet_1000.h5',\n","        'url': 'https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b4_imagenet_1000.h5',\n","        'md5': '01df77157a86609530aeb4f1f9527949',\n","    },\n","\n","    'efficientnet-b5': {\n","        'name': 'efficientnet-b5_imagenet_1000.h5',\n","        'url': 'https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b5_imagenet_1000.h5',\n","        'md5': 'c31311a1a38b5111e14457145fccdf32',\n","    }\n","\n","}\n","\n","\n","def round_filters(filters, global_params):\n","    \"\"\"Round number of filters.\"\"\"\n","    multiplier = global_params.width_coefficient\n","    divisor = global_params.depth_divisor\n","    min_depth = global_params.min_depth\n","    if not multiplier:\n","        return filters\n","\n","    filters *= multiplier\n","    min_depth = min_depth or divisor\n","    new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)\n","    # Make sure that round down does not go down by more than 10%.\n","    if new_filters < 0.9 * filters:\n","        new_filters += divisor\n","    return int(new_filters)\n","\n","\n","def round_repeats(repeats, global_params):\n","    \"\"\"Round number of repeats.\"\"\"\n","    multiplier = global_params.depth_coefficient\n","    if not multiplier:\n","        return repeats\n","    return int(math.ceil(multiplier * repeats))\n","\n","\n","def get_efficientnet_params(model_name, override_params=None):\n","    \"\"\"Get efficientnet params based on model name.\"\"\"\n","    params_dict = {\n","        # (width_coefficient, depth_coefficient, resolution, dropout_rate)\n","        # Note: the resolution here is just for reference, its values won't be used.\n","        'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n","        'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n","        'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n","        'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n","        'efficientnet-b4': (1.4, 1.8, 380, 0.3),\n","        'efficientnet-b5': (1.6, 2.2, 456, 0.3),\n","        'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n","        'efficientnet-b7': (2.0, 3.1, 600, 0.5),\n","    }\n","    if model_name not in params_dict.keys():\n","        raise KeyError('There is no model named {}.'.format(model_name))\n","\n","    width_coefficient, depth_coefficient, _, dropout_rate = params_dict[model_name]\n","\n","    blocks_args = [\n","        'r1_k3_s11_e1_i32_o16_se0.25', 'r2_k3_s22_e6_i16_o24_se0.25',\n","        'r2_k5_s22_e6_i24_o40_se0.25', 'r3_k3_s22_e6_i40_o80_se0.25',\n","        'r3_k5_s11_e6_i80_o112_se0.25', 'r4_k5_s22_e6_i112_o192_se0.25',\n","        'r1_k3_s11_e6_i192_o320_se0.25',\n","    ]\n","    global_params = GlobalParams(\n","        batch_norm_momentum=0.99,\n","        batch_norm_epsilon=1e-3,\n","        dropout_rate=dropout_rate,\n","        drop_connect_rate=0.2,\n","        num_classes=1000,\n","        width_coefficient=width_coefficient,\n","        depth_coefficient=depth_coefficient,\n","        depth_divisor=8,\n","        min_depth=None)\n","\n","    if override_params:\n","        global_params = global_params._replace(**override_params)\n","\n","    decoder = BlockDecoder()\n","    return decoder.decode(blocks_args), global_params\n","\n","\n","class BlockDecoder(object):\n","    \"\"\"Block Decoder for readability.\"\"\"\n","\n","    @staticmethod\n","    def _decode_block_string(block_string):\n","        \"\"\"Gets a block through a string notation of arguments.\"\"\"\n","        assert isinstance(block_string, str)\n","        ops = block_string.split('_')\n","        options = {}\n","        for op in ops:\n","            splits = re.split(r'(\\d.*)', op)\n","            if len(splits) >= 2:\n","                key, value = splits[:2]\n","                options[key] = value\n","\n","        if 's' not in options or len(options['s']) != 2:\n","            raise ValueError('Strides options should be a pair of integers.')\n","\n","        return BlockArgs(\n","            kernel_size=int(options['k']),\n","            num_repeat=int(options['r']),\n","            input_filters=int(options['i']),\n","            output_filters=int(options['o']),\n","            expand_ratio=int(options['e']),\n","            id_skip=('noskip' not in block_string),\n","            se_ratio=float(options['se']) if 'se' in options else None,\n","            strides=[int(options['s'][0]), int(options['s'][1])]\n","        )\n","\n","    @staticmethod\n","    def _encode_block_string(block):\n","        \"\"\"Encodes a block to a string.\"\"\"\n","        args = [\n","            'r%d' % block.num_repeat,\n","            'k%d' % block.kernel_size,\n","            's%d%d' % (block.strides[0], block.strides[1]),\n","            'e%s' % block.expand_ratio,\n","            'i%d' % block.input_filters,\n","            'o%d' % block.output_filters\n","        ]\n","        if 0 < block.se_ratio <= 1:\n","            args.append('se%s' % block.se_ratio)\n","        if block.id_skip is False:\n","            args.append('noskip')\n","        return '_'.join(args)\n","\n","    def decode(self, string_list):\n","        \"\"\"Decodes a list of string notations to specify blocks inside the network.\n","        Args:\n","          string_list: a list of strings, each string is a notation of block.\n","        Returns:\n","          A list of namedtuples to represent blocks arguments.\n","        \"\"\"\n","        assert isinstance(string_list, list)\n","        blocks_args = []\n","        for block_string in string_list:\n","            blocks_args.append(self._decode_block_string(block_string))\n","        return blocks_args\n","\n","    def encode(self, blocks_args):\n","        \"\"\"Encodes a list of Blocks to a list of strings.\n","        Args:\n","          blocks_args: A list of namedtuples to represent blocks arguments.\n","        Returns:\n","          a list of strings, each string is a notation of block.\n","        \"\"\"\n","        block_strings = []\n","        for block in blocks_args:\n","            block_strings.append(self._encode_block_string(block))\n","        return block_strings\n","\n","\n","class Swish(layers.Layer):\n","    def __init__(self, name=None, **kwargs):\n","        super().__init__(name=name, **kwargs)\n","\n","    def call(self, inputs, **kwargs):\n","        return tf.nn.swish(inputs)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config['name'] = self.name\n","        return config\n","\n","\n","def SEBlock(block_args, **kwargs):\n","    num_reduced_filters = max(\n","        1, int(block_args.input_filters * block_args.se_ratio))\n","    filters = block_args.input_filters * block_args.expand_ratio\n","\n","    spatial_dims = [1, 2]\n","\n","    try:\n","        block_name = kwargs['block_name']\n","    except KeyError:\n","        block_name = ''\n","\n","    def block(inputs):\n","        x = inputs\n","        x = layers.Lambda(lambda a: K.mean(a, axis=spatial_dims, keepdims=True))(x)\n","        x = layers.Conv2D(\n","            num_reduced_filters,\n","            kernel_size=[1, 1],\n","            strides=[1, 1],\n","            kernel_initializer=conv_kernel_initializer,\n","            padding='same',\n","            name=block_name + 'se_reduce_conv2d',\n","            use_bias=True\n","        )(x)\n","\n","        x = Swish(name=block_name + 'se_swish')(x)\n","\n","        x = layers.Conv2D(\n","            filters,\n","            kernel_size=[1, 1],\n","            strides=[1, 1],\n","            kernel_initializer=conv_kernel_initializer,\n","            padding='same',\n","            name=block_name + 'se_expand_conv2d',\n","            use_bias=True\n","        )(x)\n","\n","        x = layers.Activation('sigmoid')(x)\n","        out = layers.Multiply()([x, inputs])\n","        return out\n","\n","    return block\n","\n","\n","class DropConnect(layers.Layer):\n","\n","    def __init__(self, drop_connect_rate, **kwargs):\n","        super().__init__(**kwargs)\n","        self.drop_connect_rate = drop_connect_rate\n","\n","    def call(self, inputs, **kwargs):\n","        def drop_connect():\n","            keep_prob = 1.0 - self.drop_connect_rate\n","\n","            # Compute drop_connect tensor\n","            batch_size = tf.shape(inputs)[0]\n","            random_tensor = keep_prob\n","            random_tensor += tf.random.uniform([batch_size, 1, 1, 1], dtype=inputs.dtype)\n","            binary_tensor = tf.floor(random_tensor)\n","            output = tf.math.divide(inputs, keep_prob) * binary_tensor\n","            return output\n","\n","        return K.in_train_phase(drop_connect(), inputs, training=None)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config['drop_connect_rate'] = self.drop_connect_rate\n","        return config\n","\n","\n","def conv_kernel_initializer(shape, dtype=K.floatx()):\n","\n","    kernel_height, kernel_width, _, out_filters = shape\n","    fan_out = int(kernel_height * kernel_width * out_filters)\n","    return tf.random.normal(\n","        shape, mean=0.0, stddev=np.sqrt(2.0 / fan_out), dtype=dtype)\n","\n","\n","def dense_kernel_initializer(shape, dtype=K.floatx()):\n","    init_range = 1.0 / np.sqrt(shape[1])\n","    return tf.random.uniform(shape, -init_range, init_range, dtype=dtype)\n","\n","\n","def MBConvBlock(block_args, global_params, idx, drop_connect_rate=None):\n","    filters = block_args.input_filters * block_args.expand_ratio\n","    batch_norm_momentum = global_params.batch_norm_momentum\n","    batch_norm_epsilon = global_params.batch_norm_epsilon\n","    has_se = (block_args.se_ratio is not None) and (0 < block_args.se_ratio <= 1)\n","\n","    block_name = 'blocks_' + str(idx) + '_'\n","\n","    def block(inputs):\n","        x = inputs\n","\n","        # Expansion phase\n","        if block_args.expand_ratio != 1:\n","            expand_conv = layers.Conv2D(filters,\n","                                        kernel_size=[1, 1],\n","                                        strides=[1, 1],\n","                                        kernel_initializer=conv_kernel_initializer,\n","                                        padding='same',\n","                                        use_bias=False,\n","                                        name=block_name + 'expansion_conv2d'\n","                                        )(x)\n","            bn0 = layers.BatchNormalization(momentum=batch_norm_momentum,\n","                                            epsilon=batch_norm_epsilon,\n","                                            name=block_name + 'expansion_batch_norm')(expand_conv)\n","\n","            x = Swish(name=block_name + 'expansion_swish')(bn0)\n","\n","        # Depth-wise convolution phase\n","        kernel_size = block_args.kernel_size\n","        depthwise_conv = layers.DepthwiseConv2D(\n","            [kernel_size, kernel_size],\n","            strides=block_args.strides,\n","            depthwise_initializer=conv_kernel_initializer,\n","            padding='same',\n","            use_bias=False,\n","            name=block_name + 'depthwise_conv2d'\n","        )(x)\n","        bn1 = layers.BatchNormalization(momentum=batch_norm_momentum,\n","                                        epsilon=batch_norm_epsilon,\n","                                        name=block_name + 'depthwise_batch_norm'\n","                                        )(depthwise_conv)\n","        x = Swish(name=block_name + 'depthwise_swish')(bn1)\n","\n","        if has_se:\n","            x = SEBlock(block_args, block_name=block_name)(x)\n","\n","        # Output phase\n","        project_conv = layers.Conv2D(\n","            block_args.output_filters,\n","            kernel_size=[1, 1],\n","            strides=[1, 1],\n","            kernel_initializer=conv_kernel_initializer,\n","            padding='same',\n","            name=block_name + 'output_conv2d',\n","            use_bias=False)(x)\n","        x = layers.BatchNormalization(momentum=batch_norm_momentum,\n","                                      epsilon=batch_norm_epsilon,\n","                                      name=block_name + 'output_batch_norm'\n","                                      )(project_conv)\n","        if block_args.id_skip:\n","            if all(\n","                    s == 1 for s in block_args.strides\n","            ) and block_args.input_filters == block_args.output_filters:\n","                # only apply drop_connect if skip presents.\n","                if drop_connect_rate:\n","                    x = DropConnect(drop_connect_rate)(x)\n","                x = layers.add([x, inputs])\n","\n","        return x\n","\n","    return block\n","\n","\n","def freeze_efficientunet_first_n_blocks(model, n):\n","    mbblock_nr = 0\n","    while True:\n","        try:\n","            model.get_layer('blocks_{}_output_batch_norm'.format(mbblock_nr))\n","            mbblock_nr += 1\n","        except ValueError:\n","            break\n","\n","    all_block_names = ['blocks_{}_output_batch_norm'.format(i) for i in range(mbblock_nr)]\n","    all_block_index = []\n","    for idx, layer in enumerate(model.layers):\n","        if layer.name == all_block_names[0]:\n","            all_block_index.append(idx)\n","            all_block_names.pop(0)\n","            if len(all_block_names) == 0:\n","                break\n","    n_blocks = len(all_block_index)\n","\n","    if n <= 0:\n","        print('n is less than or equal to 0, therefore no layer will be frozen.')\n","        return\n","    if n > n_blocks:\n","        raise ValueError(\"There are {} blocks in total, n cannot be greater than {}.\".format(n_blocks, n_blocks))\n","\n","    idx_of_last_block_to_be_frozen = all_block_index[n - 1]\n","    for layer in model.layers[:idx_of_last_block_to_be_frozen + 1]:\n","        layer.trainable = False\n","\n","\n","def unfreeze_efficientunet(model):\n","    for layer in model.layers:\n","        layer.trainable = True\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bNYQxP1uXq1m"},"source":["__all__ = ['get_model_by_name', 'get_efficientnet_b0_encoder', 'get_efficientnet_b1_encoder',\n","           'get_efficientnet_b2_encoder', 'get_efficientnet_b3_encoder', 'get_efficientnet_b4_encoder',\n","           'get_efficientnet_b5_encoder', 'get_efficientnet_b6_encoder', 'get_efficientnet_b7_encoder']\n","\n","\n","def efficientnet(input_shape, blocks_args_list, global_params):\n","    batch_norm_momentum = global_params.batch_norm_momentum\n","    batch_norm_epsilon = global_params.batch_norm_epsilon\n","\n","    # Stem part\n","    model_input = layers.Input(shape=input_shape)\n","    x = layers.Conv2D(\n","        filters=round_filters(32, global_params),\n","        kernel_size=[3, 3],\n","        strides=[2, 2],\n","        kernel_initializer=conv_kernel_initializer,\n","        padding='same',\n","        use_bias=False,\n","        name='stem_conv2d'\n","    )(model_input)\n","\n","    x = layers.BatchNormalization(\n","        momentum=batch_norm_momentum,\n","        epsilon=batch_norm_epsilon,\n","        name='stem_batch_norm'\n","    )(x)\n","\n","    x = Swish(name='stem_swish')(x)\n","\n","    # Blocks part\n","    idx = 0\n","    drop_rate = global_params.drop_connect_rate\n","    n_blocks = sum([blocks_args.num_repeat for blocks_args in blocks_args_list])\n","    drop_rate_dx = drop_rate / n_blocks\n","\n","    for blocks_args in blocks_args_list:\n","        assert blocks_args.num_repeat > 0\n","        # Update block input and output filters based on depth multiplier.\n","        blocks_args = blocks_args._replace(\n","            input_filters=round_filters(blocks_args.input_filters, global_params),\n","            output_filters=round_filters(blocks_args.output_filters, global_params),\n","            num_repeat=round_repeats(blocks_args.num_repeat, global_params)\n","        )\n","\n","        # The first block needs to take care of stride and filter size increase.\n","        x = MBConvBlock(blocks_args, global_params, idx, drop_connect_rate=drop_rate_dx * idx)(x)\n","        idx += 1\n","\n","        if blocks_args.num_repeat > 1:\n","            blocks_args = blocks_args._replace(input_filters=blocks_args.output_filters, strides=[1, 1])\n","\n","        for _ in range(blocks_args.num_repeat - 1):\n","            x = MBConvBlock(blocks_args, global_params, idx, drop_connect_rate=drop_rate_dx * idx)(x)\n","            idx += 1\n","\n","    # Head part\n","    x = layers.Conv2D(\n","        filters=round_filters(1280, global_params),\n","        kernel_size=[1, 1],\n","        strides=[1, 1],\n","        kernel_initializer=conv_kernel_initializer,\n","        padding='same',\n","        use_bias=False,\n","        name='head_conv2d'\n","    )(x)\n","\n","    x = layers.BatchNormalization(\n","        momentum=batch_norm_momentum,\n","        epsilon=batch_norm_epsilon,\n","        name='head_batch_norm'\n","    )(x)\n","\n","    x = Swish(name='head_swish')(x)\n","\n","    x = layers.GlobalAveragePooling2D(name='global_average_pooling2d')(x)\n","\n","    if global_params.dropout_rate > 0:\n","        x = layers.Dropout(global_params.dropout_rate)(x)\n","\n","    x = layers.Dense(\n","        global_params.num_classes,\n","        kernel_initializer=dense_kernel_initializer,\n","        activation='softmax',\n","        name='head_dense'\n","    )(x)\n","\n","    model = models.Model(model_input, x)\n","\n","    return model\n","\n","\n","def get_model_by_name(model_name, input_shape, classes=1000, pretrained=False):\n","    \"\"\"Get an EfficientNet model by its name.\n","    \"\"\"\n","    blocks_args, global_params = get_efficientnet_params(model_name, override_params={'num_classes': classes})\n","    model = efficientnet(input_shape, blocks_args, global_params)\n","\n","    try:\n","        if pretrained:\n","            weights = IMAGENET_WEIGHTS[model_name]\n","            weights_path = get_file(\n","                weights['name'],\n","                weights['url'],\n","                cache_subdir='models',\n","                md5_hash=weights['md5'],\n","            )\n","            model.load_weights(weights_path)\n","    except KeyError as e:\n","        print(\"NOTE: Currently model {} doesn't have pretrained weights, therefore a model with randomly initialized\"\n","              \" weights is returned.\".format(e))\n","\n","    return model\n","\n","\n","def get_efficientnet_encoder(model_name, input_shape, pretrained=False):\n","    model = get_model_by_name(model_name, input_shape, pretrained=pretrained)\n","    encoder = models.Model(model.input, model.get_layer('global_average_pooling2d').output)\n","    encoder.layers.pop()  # remove GAP layer\n","    return encoder\n","\n","\n","def get_efficientnet_b0_encoder(input_shape, pretrained=False):\n","    return get_efficientnet_encoder('efficientnet-b0', input_shape, pretrained=pretrained)\n","\n","\n","def get_efficientnet_b1_encoder(input_shape, pretrained=False):\n","    return get_efficientnet_encoder('efficientnet-b1', input_shape, pretrained=pretrained)\n","\n","\n","def get_efficientnet_b2_encoder(input_shape, pretrained=False):\n","    return get_efficientnet_encoder('efficientnet-b2', input_shape, pretrained=pretrained)\n","\n","\n","def get_efficientnet_b3_encoder(input_shape, pretrained=False):\n","    return get_efficientnet_encoder('efficientnet-b3', input_shape, pretrained=pretrained)\n","\n","\n","def get_efficientnet_b4_encoder(input_shape, pretrained=False):\n","    return get_efficientnet_encoder('efficientnet-b4', input_shape, pretrained=pretrained)\n","\n","\n","def get_efficientnet_b5_encoder(input_shape, pretrained=False):\n","    return get_efficientnet_encoder('efficientnet-b5', input_shape, pretrained=pretrained)\n","\n","\n","def get_efficientnet_b6_encoder(input_shape, pretrained=False):\n","    return get_efficientnet_encoder('efficientnet-b6', input_shape, pretrained=pretrained)\n","\n","\n","def get_efficientnet_b7_encoder(input_shape, pretrained=False):\n","    return get_efficientnet_encoder('efficientnet-b7', input_shape, pretrained=pretrained)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Ju4D6ZseXhr"},"source":["## BottleNeck"]},{"cell_type":"code","metadata":{"id":"xzQhnYsi88E0"},"source":["def BottleNeck1():\n","  def call(inputs):\n","    x = Conv2D(inputs.shape[-1],kernel_size=1,padding='same',kernel_initializer='he_normal',use_bias=False)(inputs)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(0.2)(x)\n","    x = Conv2D(inputs.shape[-1],kernel_size=1,padding='same',kernel_initializer='he_normal',use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x  =LeakyReLU(0.2)(x)\n","    out= x+inputs\n","\n","    out=BatchNormalization()(out)\n","    return out\n","  return call"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f_Gc6ReclDCQ"},"source":["##Get output encoder to skip connection\n"]},{"cell_type":"code","metadata":{"id":"iNxr5oRtnUuh"},"source":["from tensorflow.keras.layers import *\n","from tensorflow.keras import models\n","\n","\n","\n","__all__ = ['get_efficient_unet_b0', 'get_efficient_unet_b1', 'get_efficient_unet_b2', 'get_efficient_unet_b3',\n","           'get_efficient_unet_b4', 'get_efficient_unet_b5', 'get_efficient_unet_b6', 'get_efficient_unet_b7',\n","           'get_blocknr_of_skip_candidates']\n","\n","\n","def get_blocknr_of_skip_candidates(encoder, verbose=False):\n","    \"\"\"\n","    Get block numbers of the blocks which will be used for concatenation in the Unet.\n","    :param encoder: the encoder\n","    :param verbose: if set to True, the shape information of all blocks will be printed in the console\n","    :return: a list of block numbers\n","    \"\"\"\n","    shapes = []\n","    candidates = []\n","    mbblock_nr = 0\n","    while True:\n","        try:\n","            mbblock = encoder.get_layer('blocks_{}_output_batch_norm'.format(mbblock_nr)).output\n","            shape = int(mbblock.shape[1]), int(mbblock.shape[2])\n","            if shape not in shapes:\n","                shapes.append(shape)\n","                candidates.append(mbblock_nr)\n","            if verbose:\n","                print('blocks_{}_output_shape: {}'.format(mbblock_nr, shape))\n","            mbblock_nr += 1\n","        except ValueError:\n","            break\n","    return candidates\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wOHAh86ICeNr"},"source":["## decoder block"]},{"cell_type":"code","metadata":{"id":"fTJvK6QiCd9e"},"source":["def ResidualBlock():\n","  def call(inputs):\n","    x = inputs\n","    indim= inputs.shape[-1]\n","    residual = Conv2D(indim,kernel_size=(3,1),padding='same')(x)\n","    residual = BatchNormalization()(residual)\n","    residual = LeakyReLU(0.2)(residual)\n","    residual = Conv2D(indim,kernel_size=(1,3),padding='same')(residual)\n","    residual = BatchNormalization()(residual)\n","    residual = LeakyReLU(0.2)(residual)\n","\n","    residual = Conv2D(indim,kernel_size=(3,1),padding='same')(residual)\n","    residual = BatchNormalization()(residual)\n","    residual = LeakyReLU(0.2)(residual)\n","    residual = Conv2D(indim,kernel_size=(1,3),padding='same')(residual)\n","    residual = BatchNormalization()(residual)\n","    residual = LeakyReLU(0.2)(residual)\n","    x        = BatchNormalization()(x)\n","    #residual = Dropout(0.2)(residual)\n","    out = x+ residual\n","    \n","    return out\n","  return call\n","#khoi giam kich thuoc skip connection\n","def dowsample_skip():\n","  def call(inputs):\n","      skip_out= Conv2D(inputs.shape[-1],kernel_size=3,strides=1,padding='same',kernel_initializer='he_normal',use_bias=False)(inputs)\n","      skip_out= BatchNormalization()(skip_out)\n","      skip_out= Activation('relu')(skip_out)\n","      skip_out = MaxPooling2D(pool_size=(2,2),strides=2)(skip_out)\n","      return skip_out\n","  return call\n","\n","#xay dung khoi decoder: \n","def Conv2DTranspose_block2(filters, transpose_kernel_size=(2, 2), upsample_rate=(2, 2),interpolation='bilinear', skip=None):\n","  def layer(input_tensor):\n","    x = Conv2DTranspose(filters, transpose_kernel_size, strides=upsample_rate, padding='same',kernel_initializer = 'he_normal')(input_tensor)\n","    out = x\n","    if skip is not None :\n","      out = Concatenate()([x, skip])\n","    out=ResidualBlock()(out)\n","    #out=Dropout(0.2)(out)\n","    return out\n","  return layer\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bF7DAfugoIx3"},"source":["##EfficientUnet version 1 \n"]},{"cell_type":"code","metadata":{"id":"gHPcDHw6XqIS"},"source":["def get_efficient_unet_vs1(encoder, out_channels=2, block_type='upsampling', concat_input=True):\n","    MBConvBlocks = []\n","    #lay cac skip connection tu encoder\n","    skip_candidates = get_blocknr_of_skip_candidates(encoder)\n","\n","    for mbblock_nr in skip_candidates:\n","        mbblock = encoder.get_layer('blocks_{}_output_batch_norm'.format(mbblock_nr)).output\n","        MBConvBlocks.append(mbblock)\n","\n","    # delete the last block since it won't be used in the process of concatenation\n","    MBConvBlocks.pop()\n","\n","    input_ = encoder.input\n","    head = encoder.get_layer('head_swish').output\n","    blocks = [input_] + MBConvBlocks + [head]\n","    #define decoder block\n","    UpBlock = Conv2DTranspose_block2\n","    \n","    #build decoder with double skip connection\n","    o = blocks.pop()\n","    o = BottleNeck1()(o)\n","    o = UpBlock(512, skip=blocks.pop())(o)\n","\n","    o = UpBlock(256, skip=blocks.pop())(o)\n","\n","\n","    o = UpBlock(128, skip=blocks.pop())(o)\n","\n","    o = UpBlock(64,  skip=blocks.pop())(o)\n","\n","    if concat_input:\n","        o = UpBlock(32, skip=blocks.pop())(o)\n","    else:\n","        o = UpBlock(32)(o)\n","    o = Conv2D(3, (1, 1), padding='same', kernel_initializer=conv_kernel_initializer,use_bias=False)(o)\n","    o = BatchNormalization()(o)\n","    o = LeakyReLU(0.2)(o)\n","    o = Conv2D(out_channels,(1, 1), padding='same',activation='sigmoid')(o)\n","    model = models.Model(encoder.input, o)\n","\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r0HhrtXL44oq"},"source":["##define cac model efficientUnet B0, B1,..."]},{"cell_type":"code","metadata":{"id":"Qu91gEdwBOiU"},"source":["def get_efficient_unet_b0(input_shape, out_channels=2, pretrained=False, block_type='transpose', concat_input=True):\n","    \"\"\"Get a Unet model with Efficient-B0 encoder\n","    :param input_shape: shape of input (cannot have None element)\n","    :param out_channels: the number of output channels\n","    :param pretrained: True for ImageNet pretrained weights\n","    :param block_type: \"upsampling\" to use UpSampling layer, otherwise use Conv2DTranspose layer\n","    :param concat_input: if True, input image will be concatenated with the last conv layer\n","    :return: an EfficientUnet_B0 model\n","    \"\"\"\n","    encoder = get_efficientnet_b0_encoder(input_shape, pretrained=pretrained)\n","    model = get_efficient_unet_vs1(encoder, out_channels, block_type=block_type, concat_input=concat_input)\n","    return model\n","def get_efficient_unet_b1(input_shape, out_channels=2, pretrained=False, block_type='transpose', concat_input=True):\n","    \"\"\"Get a Unet model with Efficient-B0 encoder\n","    :param input_shape: shape of input (cannot have None element)\n","    :param out_channels: the number of output channels\n","    :param pretrained: True for ImageNet pretrained weights\n","    :param block_type: \"upsampling\" to use UpSampling layer, otherwise use Conv2DTranspose layer\n","    :param concat_input: if True, input image will be concatenated with the last conv layer\n","    :return: an EfficientUnet_B0 model\n","    \"\"\"\n","    encoder = get_efficientnet_b1_encoder(input_shape, pretrained=pretrained)\n","    model = get_efficient_unet_vs1(encoder, out_channels, block_type=block_type, concat_input=concat_input) \n","    return model\n","def get_efficient_unet_b2(input_shape, out_channels=2, pretrained=False, block_type='transpose', concat_input=True):\n","    \"\"\"Get a Unet model with Efficient-B0 encoder\n","    :param input_shape: shape of input (cannot have None element)\n","    :param out_channels: the number of output channels\n","    :param pretrained: True for ImageNet pretrained weights\n","    :param block_type: \"upsampling\" to use UpSampling layer, otherwise use Conv2DTranspose layer\n","    :param concat_input: if True, input image will be concatenated with the last conv layer\n","    :return: an EfficientUnet_B0 model\n","    \"\"\"\n","    encoder = get_efficientnet_b2_encoder(input_shape, pretrained=pretrained)\n","    model = get_efficient_unet_vs1(encoder, out_channels, block_type=block_type, concat_input=concat_input)\n","    return model\n","def get_efficient_unet_b3(input_shape, out_channels=2, pretrained=False, block_type='transpose', concat_input=True):\n","    \"\"\"Get a Unet model with Efficient-B0 encoder\n","    :param input_shape: shape of input (cannot have None element)\n","    :param out_channels: the number of output channels\n","    :param pretrained: True for ImageNet pretrained weights\n","    :param block_type: \"upsampling\" to use UpSampling layer, otherwise use Conv2DTranspose layer\n","    :param concat_input: if True, input image will be concatenated with the last conv layer\n","    :return: an EfficientUnet_B0 model\n","    \"\"\"\n","    encoder = get_efficientnet_b3_encoder(input_shape, pretrained=pretrained)\n","    model = get_efficient_unet_vs1(encoder, out_channels, block_type=block_type, concat_input=concat_input)\n","    return model\n","def get_efficient_unet_b4(input_shape, out_channels=2, pretrained=False, block_type='transpose', concat_input=True):\n","    \"\"\"Get a Unet model with Efficient-B0 encoder\n","    :param input_shape: shape of input (cannot have None element)\n","    :param out_channels: the number of output channels\n","    :param pretrained: True for ImageNet pretrained weights\n","    :param block_type: \"upsampling\" to use UpSampling layer, otherwise use Conv2DTranspose layer\n","    :param concat_input: if True, input image will be concatenated with the last conv layer\n","    :return: an EfficientUnet_B0 model\n","    \"\"\"\n","    encoder = get_efficientnet_b4_encoder(input_shape, pretrained=pretrained)\n","    model = get_efficient_unet_vs1(encoder, out_channels, block_type=block_type, concat_input=concat_input)\n","    return model\n","def get_efficient_unet_b5(input_shape, out_channels=2, pretrained=False, block_type='transpose', concat_input=True):\n","    \"\"\"Get a Unet model with Efficient-B0 encoder\n","    :param input_shape: shape of input (cannot have None element)\n","    :param out_channels: the number of output channels\n","    :param pretrained: True for ImageNet pretrained weights\n","    :param block_type: \"upsampling\" to use UpSampling layer, otherwise use Conv2DTranspose layer\n","    :param concat_input: if True, input image will be concatenated with the last conv layer\n","    :return: an EfficientUnet_B0 model\n","    \"\"\"\n","    encoder = get_efficientnet_b5_encoder(input_shape, pretrained=pretrained)\n","    model = get_efficient_unet_vs1(encoder, out_channels, block_type=block_type, concat_input=concat_input)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Ek58RqklXdX"},"source":["## Mo-UNet"]},{"cell_type":"code","metadata":{"id":"PVzvpnaa_naY"},"source":["def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n","    '''\n","    2D Convolutional layers\n","    \n","    Arguments:\n","        x {keras layer} -- input layer \n","        filters {int} -- number of filters\n","        num_row {int} -- number of rows in filters\n","        num_col {int} -- number of columns in filters\n","    \n","    Keyword Arguments:\n","        padding {str} -- mode of padding (default: {'same'})\n","        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n","        activation {str} -- activation function (default: {'relu'})\n","        name {str} -- name of the layer (default: {None})\n","    \n","    Returns:\n","        [keras layer] -- [output layer]\n","    '''\n","\n","    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n","    x = BatchNormalization(axis=3, scale=False)(x)\n","\n","    if(activation == None):\n","        return x\n","\n","    x = Activation(activation, name=name)(x)\n","\n","    return x\n","\n","def ResPath(filters, length, inp):\n","    '''\n","    ResPath\n","    \n","    Arguments:\n","        filters {int} -- [description]\n","        length {int} -- length of ResPath\n","        inp {keras layer} -- input layer \n","    \n","    Returns:\n","        [keras layer] -- [output layer]\n","    '''\n","\n","    shortcut = inp\n","    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n","                         activation=None, padding='same')\n","\n","    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n","\n","    out = add([shortcut, out])\n","    out = Activation('relu')(out)\n","    out = BatchNormalization(axis=3)(out)\n","\n","    for i in range(length-1):\n","\n","        shortcut = out\n","        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n","                             activation=None, padding='same')\n","\n","        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n","\n","        out = add([shortcut, out])\n","        out = Activation('relu')(out)\n","        out = BatchNormalization(axis=3)(out)\n","\n","    return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Z6gI620rTNZ"},"source":["def mo_unet(input_size = (192,288,3), out_channels=2):\n","    data = Input(shape=input_size, dtype='float', name='data')\n","    mvn0 = Lambda(mvn)(data)\n","    conv1 = Conv2D(64, 3, padding = 'same')(mvn0)\n","    conv1 = Lambda(mvn)(conv1)\n","    conv1 = Activation('relu')(conv1)\n","    conv1 = Conv2D(64, 3,  padding = 'same')(conv1)\n","    conv1 = Lambda(mvn)(conv1)\n","    conv1 = Activation('relu')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    #conv1 = ResPath(64, 4, conv1)\n","\n","    conv2 = Conv2D(128, 3,  padding = 'same')(pool1)\n","    conv2 = Lambda(mvn)(conv2)\n","    conv2 = Activation('relu')(conv2)\n","    conv2 = Conv2D(128, 3,  padding = 'same')(conv2)\n","    conv2 = Lambda(mvn)(conv2)\n","    conv2 = Activation('relu')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    #conv2 = ResPath(128, 3, conv2)\n","\n","    conv3 = Conv2D(256, 3,  padding = 'same')(pool2)\n","    conv3 = Lambda(mvn)(conv3)\n","    conv3 = Activation('relu')(conv3)\n","    conv3 = Conv2D(256, 3,  padding = 'same')(conv3)\n","    conv3 = Lambda(mvn)(conv3)\n","    conv3 = Activation('relu')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    #conv3 = ResPath(256, 2, conv3)\n","    \n","    conv4 = Conv2D(512, 3,  padding = 'same')(pool3)\n","    conv4 = Lambda(mvn)(conv4)\n","    conv4 = Activation('relu')(conv4)\n","    conv4 = Conv2D(512, 3,  padding = 'same')(conv4)\n","    conv4 = Lambda(mvn)(conv4)\n","    conv4 = Activation('relu')(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    #conv4 = ResPath(512, 1, conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","    pool4 = ASPP(pool4,1024)\n","\n","    conv5 = Conv2D(1024, 3,  padding = 'same')(pool4)\n","    conv5 = Lambda(mvn)(conv5)\n","    conv5 = Activation('relu')(conv5)\n","    conv5 = Conv2D(1024, 3,  padding = 'same')(conv5)\n","    conv5 = Lambda(mvn)(conv5)\n","    conv5 = Activation('relu')(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    merge6 = attention_up_and_concate(conv5,conv4)\n","    conv6 = Conv2D(512, 3,  padding = 'same')(merge6)\n","    conv6 = Lambda(mvn)(conv6)\n","    conv6 = Activation('relu')(conv6)\n","    conv6 = Conv2D(512, 3,  padding = 'same')(conv6)\n","    conv6 = Lambda(mvn)(conv6)\n","    conv6 = Activation('relu')(conv6)\n","\n","    merge7 = attention_up_and_concate(conv6,conv3)\n","    conv7 = Conv2D(256, 3,  padding = 'same')(merge7)\n","    conv7 = Lambda(mvn)(conv7)\n","    conv7 = Activation('relu')(conv7)\n","    conv7 = Conv2D(256, 3,  padding = 'same')(conv7)\n","    conv7 = Lambda(mvn)(conv7)\n","    conv7 = Activation('relu')(conv7)\n","\n","    merge8 = attention_up_and_concate(conv7,conv2)\n","    conv8 = Conv2D(128, 3,  padding = 'same')(merge8)\n","    conv8 = Lambda(mvn)(conv8)\n","    conv8 = Activation('relu')(conv8)\n","    conv8 = Conv2D(128, 3,  padding = 'same')(conv8)\n","    conv8 = Lambda(mvn)(conv8)\n","    conv8 = Activation('relu')(conv8)\n","\n","    merge9 = attention_up_and_concate(conv8,conv1)\n","    conv9 = Conv2D(64, 3,  padding = 'same')(merge9)\n","    conv9 = Lambda(mvn)(conv9)\n","    conv9 = Activation('relu')(conv9)\n","    conv9 = Conv2D(64, 3,  padding = 'same')(conv9)\n","    conv9 = Lambda(mvn)(conv9)\n","    conv9 = Activation('relu')(conv9)\n","    conv9 = Conv2D(out_channels, 3,  padding = 'same')(conv9)\n","    conv9 = Activation('softmax')(conv9)\n","    #conv10 = Conv2D(1, 1, activation = 'softmax')(conv9)\n","\n","    model = Model(data, conv9)\n","\n","    return model\n","\n","\n","########################################################################################################\n","#Attention U-Net\n","def att_unet(input_size = (192,288,3),classnum=2,pretrained_weights = None,):\n","    data_format='channels_last'\n","    data = Input(shape=input_size, dtype='float', name='data')\n","    x = data\n","    depth = 4\n","    features = 64\n","    skips = []\n","    for i in range(depth):\n","        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n","        skips.append(x)\n","        x = MaxPooling2D((2, 2), data_format='channels_first')(x)\n","        features = features * 2\n","\n","    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n","    x = Dropout(0.2)(x)\n","    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n","\n","    for i in reversed(range(depth)):\n","        features = features // 2\n","        print(x.shape,skips[i].shape)\n","        x = attention_up_and_concate(x, skips[i], data_format=data_format)\n","        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n","        x = Dropout(0.2)(x)\n","        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n","\n","    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n","    conv7 = core.Activation('sigmoid')(conv6)\n","    model = Model(inputs=inputs, outputs=conv7)\n","\n","    #model.compile(optimizer=Adam(lr=1e-5), loss=focal_tversky, metrics=['accuracy', dice_coef])\n","    return model\n","\n","\n","########################################################################################################\n","#Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\n","def r2unet(input_size = (192,288,3),classnum=2,pretrained_weights = None,):\n","    data_format='channel_last'\n","    data = Input(shape=input_size, dtype='float', name='data')\n","    x = data\n","    depth = 4\n","    features = 64\n","    skips = []\n","    for i in range(depth):\n","        x = rec_res_block(x, features, data_format=data_format)\n","        skips.append(x)\n","        x = MaxPooling2D((2, 2), data_format=data_format)(x)\n","\n","        features = features * 2\n","\n","    x = rec_res_block(x, features, data_format=data_format)\n","\n","    for i in reversed(range(depth)):\n","        features = features // 2\n","        x = up_and_concate(x, skips[i], data_format=data_format)\n","        x = rec_res_block(x, features, data_format=data_format)\n","\n","    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n","    conv7 = core.Activation('sigmoid')(conv6)\n","    model = Model(inputs=inputs, outputs=conv7)\n","    #model.compile(optimizer=Adam(lr=1e-6), loss=[dice_coef_loss], metrics=['accuracy', dice_coef])\n","    return model\n","\n","\n","########################################################################################################\n","#Attention R2U-Net\n","def att_r2unet(input_size = (192,288,3), out_channels=2):\n","    data_format='channels_last'\n","    data = Input(shape=input_size, name='data')\n","    x = data\n","    depth = 4\n","    features = 64\n","    skips = []\n","    for i in range(depth):\n","        x = rec_res_block(x, features, data_format=data_format)\n","        skips.append(x)\n","        x = MaxPooling2D((2, 2), data_format=data_format)(x)\n","\n","        features = features * 2\n","\n","    x = rec_res_block(x, features, data_format=data_format)\n","\n","    for i in reversed(range(depth)):\n","        features = features // 2\n","        x = attention_up_and_concate(x, skips[i], data_format=data_format)\n","        x = rec_res_block(x, features, data_format=data_format)\n","\n","    conv6 = Conv2D(out_channels, (1, 1), padding='same', data_format=data_format)(x)\n","    conv6 = Activation('softmax')(conv6)\n","    model = Model(data, conv6)\n","    #model.compile(optimizer=Adam(lr=1e-6), loss=[dice_coef_loss], metrics=['accuracy', dice_coef])\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qa1zTMhrZrjG","executionInfo":{"status":"ok","timestamp":1629024225673,"user_tz":-420,"elapsed":3457,"user":{"displayName":"Hai Ninh Nham Do","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj71NWKYnSKJmvjkMKuN-TGjfdJzXtd8JZNf4r7=s64","userId":"15777938739034634289"}},"outputId":"b31fb30e-9348-4c0d-8e02-34960f6b7382"},"source":["#generator = mo_unet(input_size = (256,256,3), out_channels=2)\n","#generator.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","data (InputLayer)               [(None, 192, 288, 3) 0                                            \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 192, 288, 3)  0           data[0][0]                       \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 192, 288, 64) 1792        lambda[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 192, 288, 64) 0           conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 192, 288, 64) 0           lambda_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 192, 288, 64) 36928       activation[0][0]                 \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 192, 288, 64) 0           conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 192, 288, 64) 0           lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 96, 144, 64)  0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 96, 144, 128) 73856       max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 96, 144, 128) 0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 96, 144, 128) 0           lambda_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 96, 144, 128) 147584      activation_2[0][0]               \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 96, 144, 128) 0           conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 96, 144, 128) 0           lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 48, 72, 128)  0           activation_3[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 48, 72, 256)  295168      max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 48, 72, 256)  0           conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 48, 72, 256)  0           lambda_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 48, 72, 256)  590080      activation_4[0][0]               \n","__________________________________________________________________________________________________\n","lambda_6 (Lambda)               (None, 48, 72, 256)  0           conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 48, 72, 256)  0           lambda_6[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 24, 36, 256)  0           activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 24, 36, 512)  1180160     max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","lambda_7 (Lambda)               (None, 24, 36, 512)  0           conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 24, 36, 512)  0           lambda_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 24, 36, 512)  2359808     activation_6[0][0]               \n","__________________________________________________________________________________________________\n","lambda_8 (Lambda)               (None, 24, 36, 512)  0           conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 24, 36, 512)  0           lambda_8[0][0]                   \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 24, 36, 512)  0           activation_7[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 12, 18, 512)  0           dropout[0][0]                    \n","__________________________________________________________________________________________________\n","average_pooling2d (AveragePooli (None, 1, 1, 512)    0           max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 1, 1, 1024)   524288      average_pooling2d[0][0]          \n","__________________________________________________________________________________________________\n","lambda_9 (Lambda)               (None, 1, 1, 1024)   0           conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 12, 18, 1024) 524288      max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 12, 18, 1024) 4718592     max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 12, 18, 1024) 13107200    max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 12, 18, 1024) 25690112    max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","re_lu (ReLU)                    (None, 1, 1, 1024)   0           lambda_9[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_10 (Lambda)              (None, 12, 18, 1024) 0           conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_11 (Lambda)              (None, 12, 18, 1024) 0           conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_12 (Lambda)              (None, 12, 18, 1024) 0           conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_13 (Lambda)              (None, 12, 18, 1024) 0           conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d (UpSampling2D)    (None, 12, 18, 1024) 0           re_lu[0][0]                      \n","__________________________________________________________________________________________________\n","re_lu_1 (ReLU)                  (None, 12, 18, 1024) 0           lambda_10[0][0]                  \n","__________________________________________________________________________________________________\n","re_lu_2 (ReLU)                  (None, 12, 18, 1024) 0           lambda_11[0][0]                  \n","__________________________________________________________________________________________________\n","re_lu_3 (ReLU)                  (None, 12, 18, 1024) 0           lambda_12[0][0]                  \n","__________________________________________________________________________________________________\n","re_lu_4 (ReLU)                  (None, 12, 18, 1024) 0           lambda_13[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 12, 18, 5120) 0           up_sampling2d[0][0]              \n","                                                                 re_lu_1[0][0]                    \n","                                                                 re_lu_2[0][0]                    \n","                                                                 re_lu_3[0][0]                    \n","                                                                 re_lu_4[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 12, 18, 1024) 5242880     concatenate[0][0]                \n","__________________________________________________________________________________________________\n","lambda_14 (Lambda)              (None, 12, 18, 1024) 0           conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","re_lu_5 (ReLU)                  (None, 12, 18, 1024) 0           lambda_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 12, 18, 1024) 9438208     re_lu_5[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_15 (Lambda)              (None, 12, 18, 1024) 0           conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 12, 18, 1024) 0           lambda_15[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 12, 18, 1024) 9438208     activation_8[0][0]               \n","__________________________________________________________________________________________________\n","lambda_16 (Lambda)              (None, 12, 18, 1024) 0           conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 12, 18, 1024) 0           lambda_16[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 24, 36, 1024) 0           activation_9[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 24, 36, 256)  131328      activation_7[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 24, 36, 256)  262400      up_sampling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 24, 36, 256)  0           conv2d_16[0][0]                  \n","                                                                 conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 24, 36, 256)  0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 24, 36, 1)    257         activation_10[0][0]              \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 24, 36, 1)    0           conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","multiply (Multiply)             (None, 24, 36, 512)  0           activation_7[0][0]               \n","                                                                 activation_11[0][0]              \n","__________________________________________________________________________________________________\n","lambda_17 (Lambda)              (None, 24, 36, 1536) 0           up_sampling2d_1[0][0]            \n","                                                                 multiply[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 24, 36, 512)  7078400     lambda_17[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_18 (Lambda)              (None, 24, 36, 512)  0           conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 24, 36, 512)  0           lambda_18[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 24, 36, 512)  2359808     activation_12[0][0]              \n","__________________________________________________________________________________________________\n","lambda_19 (Lambda)              (None, 24, 36, 512)  0           conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 24, 36, 512)  0           lambda_19[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 48, 72, 512)  0           activation_13[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 48, 72, 128)  32896       activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 48, 72, 128)  65664       up_sampling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 48, 72, 128)  0           conv2d_21[0][0]                  \n","                                                                 conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 48, 72, 128)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 48, 72, 1)    129         activation_14[0][0]              \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 48, 72, 1)    0           conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_1 (Multiply)           (None, 48, 72, 256)  0           activation_5[0][0]               \n","                                                                 activation_15[0][0]              \n","__________________________________________________________________________________________________\n","lambda_20 (Lambda)              (None, 48, 72, 768)  0           up_sampling2d_2[0][0]            \n","                                                                 multiply_1[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 48, 72, 256)  1769728     lambda_20[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_21 (Lambda)              (None, 48, 72, 256)  0           conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 48, 72, 256)  0           lambda_21[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 48, 72, 256)  590080      activation_16[0][0]              \n","__________________________________________________________________________________________________\n","lambda_22 (Lambda)              (None, 48, 72, 256)  0           conv2d_25[0][0]                  \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 48, 72, 256)  0           lambda_22[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 96, 144, 256) 0           activation_17[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 96, 144, 64)  8256        activation_3[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 96, 144, 64)  16448       up_sampling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 96, 144, 64)  0           conv2d_26[0][0]                  \n","                                                                 conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 96, 144, 64)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 96, 144, 1)   65          activation_18[0][0]              \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 96, 144, 1)   0           conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_2 (Multiply)           (None, 96, 144, 128) 0           activation_3[0][0]               \n","                                                                 activation_19[0][0]              \n","__________________________________________________________________________________________________\n","lambda_23 (Lambda)              (None, 96, 144, 384) 0           up_sampling2d_3[0][0]            \n","                                                                 multiply_2[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 96, 144, 128) 442496      lambda_23[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_24 (Lambda)              (None, 96, 144, 128) 0           conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 96, 144, 128) 0           lambda_24[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_30 (Conv2D)              (None, 96, 144, 128) 147584      activation_20[0][0]              \n","__________________________________________________________________________________________________\n","lambda_25 (Lambda)              (None, 96, 144, 128) 0           conv2d_30[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 96, 144, 128) 0           lambda_25[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_4 (UpSampling2D)  (None, 192, 288, 128 0           activation_21[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_31 (Conv2D)              (None, 192, 288, 32) 2080        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_32 (Conv2D)              (None, 192, 288, 32) 4128        up_sampling2d_4[0][0]            \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 192, 288, 32) 0           conv2d_31[0][0]                  \n","                                                                 conv2d_32[0][0]                  \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 192, 288, 32) 0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_33 (Conv2D)              (None, 192, 288, 1)  33          activation_22[0][0]              \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 192, 288, 1)  0           conv2d_33[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_3 (Multiply)           (None, 192, 288, 64) 0           activation_1[0][0]               \n","                                                                 activation_23[0][0]              \n","__________________________________________________________________________________________________\n","lambda_26 (Lambda)              (None, 192, 288, 192 0           up_sampling2d_4[0][0]            \n","                                                                 multiply_3[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_34 (Conv2D)              (None, 192, 288, 64) 110656      lambda_26[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_27 (Lambda)              (None, 192, 288, 64) 0           conv2d_34[0][0]                  \n","__________________________________________________________________________________________________\n","activation_24 (Activation)      (None, 192, 288, 64) 0           lambda_27[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_35 (Conv2D)              (None, 192, 288, 64) 36928       activation_24[0][0]              \n","__________________________________________________________________________________________________\n","lambda_28 (Lambda)              (None, 192, 288, 64) 0           conv2d_35[0][0]                  \n","__________________________________________________________________________________________________\n","activation_25 (Activation)      (None, 192, 288, 64) 0           lambda_28[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_36 (Conv2D)              (None, 192, 288, 2)  1154        activation_25[0][0]              \n","__________________________________________________________________________________________________\n","activation_26 (Activation)      (None, 192, 288, 2)  0           conv2d_36[0][0]                  \n","==================================================================================================\n","Total params: 86,429,670\n","Trainable params: 86,429,670\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FtJwR6GvxJSn"},"source":["## Seg-UNet"]},{"cell_type":"code","metadata":{"id":"x7ZSKpmTqb2m"},"source":["class MaxPoolingWithArgmax2D(Layer):\n","    def __init__(self, pool_size=(2, 2), strides=(2, 2), padding='same', **kwargs):\n","        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n","        self.padding = padding\n","        self.pool_size = pool_size\n","        self.strides = strides\n","\n","    def call(self, inputs, **kwargs):\n","        padding = self.padding\n","        pool_size = self.pool_size\n","        strides = self.strides\n","        if K.backend() == 'tensorflow':\n","            ksize = [1, pool_size[0], pool_size[1], 1]\n","            padding = padding.upper()\n","            strides = [1, strides[0], strides[1], 1]\n","            output, argmax = tf.nn.max_pool_with_argmax(inputs, ksize=ksize, strides=strides, padding=padding)\n","        else:\n","            errmsg = '{} backend is not supported for layer {}'.format(K.backend(), type(self).__name__)\n","            raise NotImplementedError(errmsg)\n","        argmax = K.cast(argmax, K.floatx())\n","        return [output, argmax]\n","\n","    def compute_output_shape(self, input_shape):\n","        ratio = (1, 2, 2, 1)\n","        output_shape = [dim // ratio[idx] if dim is not None else None for idx, dim in enumerate(input_shape)]\n","        output_shape = tuple(output_shape)\n","        return [output_shape, output_shape]\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return 2 * [None]\n","\n","\n","class MaxUnpooling2D(Layer):\n","    def __init__(self, size=(2, 2), **kwargs):\n","        super(MaxUnpooling2D, self).__init__(**kwargs)\n","        self.size = size\n","\n","    def call(self, inputs, output_shape=None):\n","        updates, mask = inputs[0], inputs[1]\n","        with tf.compat.v1.variable_scope(self.name):\n","            mask = K.cast(mask, 'int32')\n","            input_shape = tf.shape(updates, out_type='int32')\n","            #  calculation new shape\n","            if output_shape is None:\n","                output_shape = (input_shape[0], input_shape[1] * self.size[0], input_shape[2] * self.size[1], input_shape[3])\n","            self.output_shape1 = output_shape\n","\n","            # calculation indices for batch, height, width and feature maps\n","            one_like_mask = K.ones_like(mask, dtype='int32')\n","            batch_shape = K.concatenate([[input_shape[0]], [1], [1], [1]], axis=0)\n","            batch_range = K.reshape(tf.range(output_shape[0], dtype='int32'), shape=batch_shape)\n","            b = one_like_mask * batch_range\n","            y = mask // (output_shape[2] * output_shape[3])\n","            x = (mask // output_shape[3]) % output_shape[2]\n","            feature_range = tf.range(output_shape[3], dtype='int32')\n","            f = one_like_mask * feature_range\n","\n","            # transpose indices & reshape update values to one dimension\n","            updates_size = tf.size(updates)\n","            indices = K.transpose(K.reshape(K.stack([b, y, x, f]), [4, updates_size]))\n","            values = K.reshape(updates, [updates_size])\n","            ret = tf.scatter_nd(indices, values, output_shape)\n","            return ret\n","\n","    def compute_output_shape(self, input_shape):\n","        mask_shape = input_shape[1]\n","        return mask_shape[0], mask_shape[1] * self.size[0], mask_shape[2] * self.size[1], mask_shape[3]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KKj28wdCxLeu"},"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input\n","from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape, Permute\n","from tensorflow.keras.layers import Convolution2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import Multiply, Concatenate\n","from keras.utils import np_utils\n","import tensorflow as tf\n","\n","#from Mylayers import MaxPoolingWithArgmax2D, MaxUnpooling2D\n","\n","\n","def CreateSegUNet(input_shape, n_labels, kernel=3, pool_size=(2, 2), output_mode=\"softmax\"):\n","    inputs = Input(shape=input_shape)\n","\n","    # encoder\n","    conv_1 = Convolution2D(64, (kernel, kernel), padding=\"same\")(inputs)\n","    conv_1 = BatchNormalization()(conv_1)\n","    conv_1 = Activation(\"relu\")(conv_1)\n","    conv_2 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_1)\n","    conv_2 = BatchNormalization()(conv_2)\n","    conv_2 = Activation(\"relu\")(conv_2)\n","\n","    pool_1, mask_1 = MaxPoolingWithArgmax2D(pool_size)(conv_2)\n","\n","    conv_3 = Convolution2D(128, (kernel, kernel), padding=\"same\")(pool_1)\n","    conv_3 = BatchNormalization()(conv_3)\n","    conv_3 = Activation(\"relu\")(conv_3)\n","    conv_4 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_3)\n","    conv_4 = BatchNormalization()(conv_4)\n","    conv_4 = Activation(\"relu\")(conv_4)\n","\n","    pool_2, mask_2 = MaxPoolingWithArgmax2D(pool_size)(conv_4)\n","\n","    conv_5 = Convolution2D(256, (kernel, kernel), padding=\"same\")(pool_2)\n","    conv_5 = BatchNormalization()(conv_5)\n","    conv_5 = Activation(\"relu\")(conv_5)\n","    conv_6 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_5)\n","    conv_6 = BatchNormalization()(conv_6)\n","    conv_6 = Activation(\"relu\")(conv_6)\n","    conv_7 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_6)\n","    conv_7 = BatchNormalization()(conv_7)\n","    conv_7 = Activation(\"relu\")(conv_7)\n","\n","    pool_3, mask_3 = MaxPoolingWithArgmax2D(pool_size)(conv_7)\n","\n","    conv_8 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_3)\n","    conv_8 = BatchNormalization()(conv_8)\n","    conv_8 = Activation(\"relu\")(conv_8)\n","    conv_9 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_8)\n","    conv_9 = BatchNormalization()(conv_9)\n","    conv_9 = Activation(\"relu\")(conv_9)\n","    conv_10 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_9)\n","    conv_10 = BatchNormalization()(conv_10)\n","    conv_10 = Activation(\"relu\")(conv_10)\n","\n","    pool_4, mask_4 = MaxPoolingWithArgmax2D(pool_size)(conv_10)\n","\n","    conv_11 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_4)\n","    conv_11 = BatchNormalization()(conv_11)\n","    conv_11 = Activation(\"relu\")(conv_11)\n","    conv_12 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_11)\n","    conv_12 = BatchNormalization()(conv_12)\n","    conv_12 = Activation(\"relu\")(conv_12)\n","    conv_13 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_12)\n","    conv_13 = BatchNormalization()(conv_13)\n","    conv_13 = Activation(\"relu\")(conv_13)\n","\n","    pool_5, mask_5 = MaxPoolingWithArgmax2D(pool_size)(conv_13)\n","    print(\"Build enceder done..\")\n","\n","    # between encoder and decoder\n","    conv_14 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_5)\n","    conv_14 = BatchNormalization()(conv_14)\n","    conv_14 = Activation(\"relu\")(conv_14)\n","    conv_15 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_14)\n","    conv_15 = BatchNormalization()(conv_15)\n","    conv_15 = Activation(\"relu\")(conv_15)\n","    conv_16 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_15)\n","    conv_16 = BatchNormalization()(conv_16)\n","    conv_16 = Activation(\"relu\")(conv_16)\n","\n","    # decoder\n","    unpool_1 = tfa.layers.MaxUnpooling2D(pool_size)(conv_16, mask_5) #########\n","    concat_1 = Concatenate()([unpool_1, conv_13])\n","\n","    conv_17 = Convolution2D(512, (kernel, kernel), padding=\"same\")(concat_1)\n","    conv_17 = BatchNormalization()(conv_17)\n","    conv_17 = Activation(\"relu\")(conv_17)\n","    conv_18 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_17)\n","    conv_18 = BatchNormalization()(conv_18)\n","    conv_18 = Activation(\"relu\")(conv_18)\n","    conv_19 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_18)\n","    conv_19 = BatchNormalization()(conv_19)\n","    conv_19 = Activation(\"relu\")(conv_19)\n","\n","    unpool_2 = tfa.layers.MaxUnpooling2D(pool_size)(conv_19, mask_4)\n","    concat_2 = Concatenate()([unpool_2, conv_10])\n","\n","    conv_20 = Convolution2D(512, (kernel, kernel), padding=\"same\")(concat_2)\n","    conv_20 = BatchNormalization()(conv_20)\n","    conv_20 = Activation(\"relu\")(conv_20)\n","    conv_21 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_20)\n","    conv_21 = BatchNormalization()(conv_21)\n","    conv_21 = Activation(\"relu\")(conv_21)\n","    conv_22 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_21)\n","    conv_22 = BatchNormalization()(conv_22)\n","    conv_22 = Activation(\"relu\")(conv_22)\n","\n","    unpool_3 = tfa.layers.MaxUnpooling2D(pool_size)(conv_22, mask_3)\n","    concat_3 = Concatenate()([unpool_3, conv_7])\n","\n","    conv_23 = Convolution2D(256, (kernel, kernel), padding=\"same\")(concat_3)\n","    conv_23 = BatchNormalization()(conv_23)\n","    conv_23 = Activation(\"relu\")(conv_23)\n","    conv_24 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_23)\n","    conv_24 = BatchNormalization()(conv_24)\n","    conv_24 = Activation(\"relu\")(conv_24)\n","    conv_25 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_24)\n","    conv_25 = BatchNormalization()(conv_25)\n","    conv_25 = Activation(\"relu\")(conv_25)\n","\n","    unpool_4 = tfa.layers.MaxUnpooling2D(pool_size)(conv_25, mask_2)\n","    concat_4 = Concatenate()([unpool_4, conv_4])\n","\n","    conv_26 = Convolution2D(128, (kernel, kernel), padding=\"same\")(concat_4)\n","    conv_26 = BatchNormalization()(conv_26)\n","    conv_26 = Activation(\"relu\")(conv_26)\n","    conv_27 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_26)\n","    conv_27 = BatchNormalization()(conv_27)\n","    conv_27 = Activation(\"relu\")(conv_27)\n","\n","    unpool_5 = tfa.layers.MaxUnpooling2D(pool_size)(conv_27, mask_1)\n","    concat_5 = Concatenate()([unpool_5, conv_2])\n","\n","    conv_28 = Convolution2D(64, (kernel, kernel), padding=\"same\")(concat_5)\n","    conv_28 = BatchNormalization()(conv_28)\n","    conv_28 = Activation(\"relu\")(conv_28)\n","\n","    conv_29 = Convolution2D(n_labels, (1, 1), padding=\"valid\")(conv_28)\n","    conv_29 = BatchNormalization()(conv_29)\n","    conv_29 = Reshape((input_shape[0] * input_shape[1], n_labels), input_shape=(input_shape[0], input_shape[1], n_labels))(conv_29)\n","\n","    outputs = Activation(output_mode)(conv_29)\n","    print(\"Build decoder done..\")\n","\n","    segunet = Model(inputs=inputs, outputs=outputs, name=\"SegUNet\")\n","\n","    return segunet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H5MrWYHvxP4N"},"source":["#generator = CreateSegUNet(input_shape=(192,288,3), n_labels=2, kernel=3, pool_size=(2, 2), output_mode=\"softmax\")\n","#generator.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tKJ4vaCpn9wI"},"source":["## Global Convolution Block"]},{"cell_type":"code","metadata":{"id":"j4WtqvLhmqnB"},"source":["def GlobalConvBlock(x, filters, size):\n","  #Global Conv Block for GCN\n","    \n","  x1 = Conv2D(filters, kernel_size=[size, 1], padding='same')(x) #padding 1,0\n","  x1 = Conv2D(filters, kernel_size=[1, size], padding='same')(x1) #padding 0,1\n","\n","  x2 = Conv2D(filters, kernel_size=[1, size], padding='same')(x) #padding 0,1\n","  x2 = Conv2D(filters, kernel_size=[size, 1], padding='same')(x2) ##padding 1,0\n","\n","  x = tf.add(x1,x2)\n","  return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W7a7x1HTnGhA"},"source":["def downsample(x, filters, size, apply_batchnorm=True):\n","  initializer = tf.random_normal_initializer(0., 0.02)\n","\n","  x = Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False)(x)\n","  if apply_batchnorm:\n","    x = BatchNormalization()(x)\n","  x = ReLU()(x)\n","  return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fd5S-msinJrB"},"source":["def downsample_gcn(x, filters, size):\n","  #initializer = tf.random_normal_initializer(0., 0.02)\n","\n","  x = GlobalConvBlock(x, filters, size)\n","  x = BatchNormalization()(x)\n","  x = ReLU()(x)\n","  return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sfkLR5PfoE-B"},"source":["## Pix2Pix Discriminator"]},{"cell_type":"code","metadata":{"id":"d3syLtoQIkfI"},"source":["def Discriminator1():\n","  initializer = tf.random_normal_initializer(0., 0.02)\n","\n","  inp = Input(shape=[192,288,3], name='input_image')\n","  tar = Input(shape=[192,288,2], name='target_image')\n","\n","  x = tf.keras.layers.concatenate([inp, tar])  # (bs, 256, 256, channels*2)\n","\n","  down1 = downsample(x, 64, 4, False)  # (bs, 128, 128, 64)\n","  down1 = downsample_gcn(down1, 128, 13)  # (bs, 128, 128, 128)\n","  down2 = downsample(down1, 128, 4)  # (bs, 64, 64, 128)\n","  down2 = downsample_gcn(down2, 256, 11) #(bs, 64, 64, 256)\n","  down3 = downsample(down2, 256, 4) #(bs, 32, 32, 256)\n","  #down3 = downsample_gcn(down3, 512, 9) #(bs, 32, 32, 512)\n","  #down4 = downsample(down3, 512, 4) #(bs, 16, 16, 512)\n","\n","\n","  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (bs, 34, 34, 256)\n","  conv = tf.keras.layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(zero_pad1)  # (bs, 31, 31, 512)\n","\n","  batchnorm1 = BatchNormalization()(conv)\n","  relu = ReLU()(batchnorm1)\n","  zero_pad2 = ZeroPadding2D()(relu)  # (bs, 33, 33, 512)\n","\n","  last = Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2)  # (bs, 30, 30, 1)\n","\n","  return tf.keras.Model(inputs=[inp, tar], outputs=last)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q80AVcfQoEPw"},"source":["def Discriminator():\n","  initializer = tf.random_normal_initializer(0., 0.02)\n","\n","  inp = Input(shape=[192,288,3], name='input_image')\n","  tar = Input(shape=[192,288,1], name='target_image')\n","\n","  x = tf.keras.layers.concatenate([inp, tar])  # (bs, 256, 256, 5)\n","\n","  down1 = downsample(x, 64, 4, False)  # (bs, 128, 128, 64)\n","  #down1 = downsample_gcn(down1, 128, 3)  # (bs, 128, 128, 128)\n","  down1 = ZeroPadding2D()(down1)\n","  #maxpool1 = tf.keras.layers.MaxPooling2D()(down1)\n","\n","  down2 = downsample(down1, 128, 4)  # (bs, 64, 64, 128)\n","  #down2 = downsample_gcn(down2, 256, 3) #(bs, 64, 64, 256)\n","  down2 = ZeroPadding2D()(down2)\n","  #maxpool2 = tf.keras.layers.MaxPooling2D()(down2)\n","\n","  down3 = downsample(down2, 256, 4) #(bs, 32, 32, 256)\n","  #down3 = downsample_gcn(down3, 512, 3) #(bs, 32, 32, 512)\n","  down3 = ZeroPadding2D()(down3)\n","  #maxpool3 = tf.keras.layers.MaxPooling2D()(down3)\n","  #zero_pad1 = ZeroPadding2D()(down3_1)  # (bs, 34, 34, 256)\n","\n","  down4 = downsample(down3, 512, 4) #(bs, 16, 16, 512)\n","  #down4 = downsample_gcn(down4, 1024, 3)\n","  #down4 = tf.keras.layers.AveragePooling2D()(down4)\n","\n","  #zero_pad1 = ZeroPadding2D()(down3)  # (bs, 34, 34, 256)\n","  #conv = Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(zero_pad1)  # (bs, 31, 31, 512)\n","\n","  #batchnorm1 = BatchNormalization()(conv)\n","  #relu = ReLU()(batchnorm1)\n","  #zero_pad2 = ZeroPadding2D()(relu)  # (bs, 33, 33, 512)\n","\n","  down4 = Dense(256)(down4)\n","  down4 = Dense(64)(down4)\n","  down4 = Dense(1)(down4)\n","\n","  #last = Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2)  # (bs, 30, 30, 1)\n","  #last = tf.keras.layers.concatenate([Flatten()(x), Flatten()(down1), 2*Flatten()(down2), 2*Flatten()(down3), 4*Flatten()(down4)])\n","\n","  return tf.keras.Model(inputs=[inp, tar], outputs=down4)"],"execution_count":null,"outputs":[]}]}