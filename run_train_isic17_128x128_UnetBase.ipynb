{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_train_isic17_128x128_UnetBase.ipynb","provenance":[],"collapsed_sections":["AROZhkRBPdrl"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"matqiSE04ofO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625818731905,"user_tz":-420,"elapsed":26702,"user":{"displayName":"Thao Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxyQEpqpUBNdqBvzi0GynfA3nhdEmshxayCtAFxA=s64","userId":"07015500522590224135"}},"outputId":"e5983d8b-8a24-4310-be22-c2ad33c2f7e2"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7beHcqdY7C93","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625818753322,"user_tz":-420,"elapsed":12164,"user":{"displayName":"Thao Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxyQEpqpUBNdqBvzi0GynfA3nhdEmshxayCtAFxA=s64","userId":"07015500522590224135"}},"outputId":"d3e59db6-0375-4d45-db03-31e3e773c522"},"source":["!pip install tfa-nightly\n","!pip install tensorflow-addons\n","!pip install import-ipynb"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tfa-nightly\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/c6/b61e8713fba40ba1046fd984639975b19ce953a449cd95b74ae4e0be945f/tfa_nightly-0.14.0.dev20210707103333-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1MB)\n","\r\u001b[K     |▎                               | 10kB 22.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 28.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 21.3MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 17.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 8.4MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 9.7MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 9.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92kB 10.0MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 8.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 8.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 122kB 8.1MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 153kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 163kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 184kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 194kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 204kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 215kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 225kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 235kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 245kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 256kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 266kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 286kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 296kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 307kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 317kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 327kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 337kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 348kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 358kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 368kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 378kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 389kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 399kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 409kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 419kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 430kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 440kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 450kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 460kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 471kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 481kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 491kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 501kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 512kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 522kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 532kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 542kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 552kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 563kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 573kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 583kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 593kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 604kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 614kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 624kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 634kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 645kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 655kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 665kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 675kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 686kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 696kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 706kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 716kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 727kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 737kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 747kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 757kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 768kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 778kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 788kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 798kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 808kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 819kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 829kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 839kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 849kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 860kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 870kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 880kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 890kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 901kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 911kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 921kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 931kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 942kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 952kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 962kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 972kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 983kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 993kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.0MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.0MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 8.1MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tfa-nightly) (2.7.1)\n","Installing collected packages: tfa-nightly\n","Successfully installed tfa-nightly-0.14.0.dev20210707103333\n","Collecting tensorflow-addons\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n","\u001b[K     |████████████████████████████████| 686kB 8.4MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.13.0\n","Collecting import-ipynb\n","  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n","Building wheels for collected packages: import-ipynb\n","  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp37-none-any.whl size=2976 sha256=9035860ff0bafa5cdc18d5c71030d36d7e8a0f615dbeaea0a7162a835e260e24\n","  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n","Successfully built import-ipynb\n","Installing collected packages: import-ipynb\n","Successfully installed import-ipynb-0.1.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TxnOnaOJ62yR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625818805601,"user_tz":-420,"elapsed":6,"user":{"displayName":"Thao Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxyQEpqpUBNdqBvzi0GynfA3nhdEmshxayCtAFxA=s64","userId":"07015500522590224135"}},"outputId":"1fe3c7aa-9f73-41da-aa47-5aa99a77bb86"},"source":["import tensorflow.keras\n","import tensorflow.keras.layers as layers\n","from tensorflow.keras.layers import *\n","import tensorflow.keras.models as models\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications import *\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.regularizers import l1, l2\n","from tensorflow.keras.utils import get_file\n","from tensorflow.keras.losses import mae\n","from tensorflow.keras import backend as K\n","import tensorflow_addons as tfa\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm, tqdm_notebook\n","\n","import tensorflow as tf\n","from tensorflow.python.framework import ops\n","from tensorflow.python.ops import array_ops, math_ops, nn_ops, standard_ops\n","import os\n","import scipy.io as sio\n","import re\n","import time\n","from collections import namedtuple\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from IPython.display import clear_output\n","import math\n","import glob\n","import sys\n","import cv2\n","from matplotlib import pyplot as plt\n","import matplotlib.image as mpimg\n","\n","from tqdm import tqdm\n","from fastprogress.fastprogress import master_bar, progress_bar\n","from time import sleep\n","%matplotlib inline\n","%cd /content/drive/MyDrive/Pix2Pix-for-Semantic-Segmentation-of-Satellite-Images/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1Y_1PLKCUNVJAVLAZcJRgszel5vRSofus/Pix2Pix-for-Semantic-Segmentation-of-Satellite-Images\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x-0ymWlWKgRa"},"source":["# %run UnetModel.ipynb\n","# %run MumfordLoss.ipynb\n","# %run augmentation.ipynb\n","# %run augment_data.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5uC-TismT_ev"},"source":["import tensorflow as tf\n","import numpy as np\n","import tensorflow_addons as tfa\n","\n","def flip(image,mask):\n","  \n","  if tf.cast(tf.random.uniform([], maxval=2, dtype=tf.int32), tf.bool):\n","    image = tf.image.flip_left_right(image)\n","    mask = tf.image.flip_left_right(mask)\n","  \n","  if tf.cast(tf.random.uniform([], maxval=2, dtype=tf.int32), tf.bool):\n","    image = tf.image.flip_up_down(image)\n","    mask = tf.image.flip_up_down(mask)\n","  return image, mask\n","def brightness(image, mask):\n","\n","  \"\"\"\n","  Randomly applies a random brightness change.\n","  \"\"\"\n","  cond_brightness = tf.cast(tf.random.uniform([], maxval=2, dtype=tf.int32), tf.bool)\n","  image = tf.cond(cond_brightness, lambda: tf.image.random_brightness(\n","      image, 0.2), lambda: tf.identity(image))\n","  return image, mask\n","\n","\n","def contrast(image, mask):\n","\n","  \"\"\"\n","  Randomly applies a random contrast change.\n","  \"\"\"\n","  cond_contrast = tf.cast(tf.random.uniform([], maxval=2, dtype=tf.int32), tf.bool)\n","  image = tf.cond(cond_contrast, lambda: tf.image.random_contrast(\n","      image, 0.1, 0.8), lambda: tf.identity(image))\n","  return image, mask\n","\n","\n","def saturation(image, mask):\n","\n","  \"\"\"\n","  Randomly applies a random saturation change.\n","  \"\"\"\n","  cond_saturation = tf.cast(tf.random.uniform([], maxval=2, dtype=tf.int32), tf.bool)\n","  image = tf.cond(cond_saturation, lambda: tf.image.random_saturation(\n","      image, 0.1, 0.5), lambda: tf.identity(image))\n","  return image, mask\n","\n","def rotate_image(image, mask,angle=30):\n","\n","  if tf.cast(tf.random.uniform([], maxval=2, dtype=tf.int32), tf.bool):\n","    comb = tf.concat([image,mask],axis=-1)\n","    comb = tfa.image.rotate(comb, angles=np.random.uniform(-angle, angle)*np.math.pi / 180)\n","    image,mask =  tf.split(comb, [image.shape[-1], mask.shape[-1]], axis=-1)\n","  return image, mask\n","def normalize(image,mask):\n","  image = tf.cast(image, tf.float32) / 255.0\n","  return image,mask\n","\n","def gen_image_aug(image,mask):\n","  image, mask = brightness(image,mask)\n","  #image, mask = saturation(image,mask)\n","  image, mask = flip(image,mask)\n","  image, mask = rotate_image(image,mask)\n","  image, mask = normalize(image, mask)\n","  return image, mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tGhKGmE85XcU"},"source":["import keras.backend as K\n","\n","def dice_coef(y_true, y_pred, smooth=1e-10):\n","    '''Average dice coefficient per batch.'''\n","    axes = (1,2,3)\n","    intersection = K.sum(y_true * y_pred, axis=axes)\n","    summation = K.sum(y_true + y_pred, axis=axes)\n","    return K.mean((2.0 * intersection + smooth) / (summation + smooth), axis=0)\n","\n","def jaccard_coef(y_true, y_pred, smooth=1e-10):\n","    '''Average jaccard coefficient per batch.'''\n","    axes = (1,2,3)\n","    intersection = K.sum(y_true * y_pred, axis=axes)\n","    union = K.sum(y_true + y_pred, axis=axes) - intersection\n","    return K.mean( (intersection + smooth) / (union + smooth), axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"muwmP1U46HCr"},"source":["# #x =  np.load(\"Dataset/x_2018.npy\")\n","# #y = np.load(\"Dataset/y_2018.npy\")\n","# #from sklearn.model_selection import train_test_split\n","# #x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state =42)\n","# x_train =  np.load(\"Dataset/x_train_2017.npy\")\n","# x_train=tf.convert_to_tensor(x_train,tf.float32)\n","\n","# y_train =  np.load(\"Dataset/y_train_2017.npy\")\n","# y_train=tf.convert_to_tensor(y_train,tf.float32)\n","\n","# x_test =  np.load(\"Dataset/x_test_2017.npy\")\n","# x_test=tf.convert_to_tensor(x_test,tf.float32)\n","\n","# y_test =  np.load(\"Dataset/y_test_2017.npy\")\n","# y_test=tf.convert_to_tensor(y_test,tf.float32)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FhdT-3xYGLC-","executionInfo":{"status":"ok","timestamp":1625818856558,"user_tz":-420,"elapsed":14670,"user":{"displayName":"Thao Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxyQEpqpUBNdqBvzi0GynfA3nhdEmshxayCtAFxA=s64","userId":"07015500522590224135"}},"outputId":"450805f4-11b4-4bc7-9d25-f55ab2b4a4eb"},"source":["# Dữ liệu:\n","# https://drive.google.com/drive/folders/1ey_xaLoqWAi7pRR9akBSjp6uqirPOpFQ?usp=sharing\n","data_folder='/content/drive/My Drive/Database/data_ISIC2017/data_ISIC2017/'\n","x_train= np.load(data_folder+'x_train2017_128.npy')\n","mask_train_0= np.load(data_folder+'y_train2017_128.npy')\n","\n","x_test= np.load(data_folder+'x_test2017_128.npy')\n","mask_test_0= np.load(data_folder+'y_test2017_128.npy')\n","print(x_train.shape,mask_train_0.shape, mask_test_0.shape)\n","\n","y_train=mask_train_0.reshape(mask_train_0.shape[0],mask_train_0.shape[1],mask_train_0.shape[2],1)\n","# mask_dev=mask_dev_0.reshape(mask_dev_0.shape[0],mask_dev_0.shape[1],mask_dev_0.shape[2],1)\n","y_test=mask_test_0.reshape(mask_test_0.shape[0],mask_test_0.shape[1],mask_test_0.shape[2],1)\n","print(x_train.shape,y_train.shape, y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(2000, 128, 128, 3) (2000, 128, 128) (600, 128, 128)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c4OfUUJphBpX"},"source":["# x_test_org=x_test\n","# y_test_org=y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TwhLdAHMGQlh","executionInfo":{"status":"ok","timestamp":1625818867633,"user_tz":-420,"elapsed":288,"user":{"displayName":"Thao Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhxyQEpqpUBNdqBvzi0GynfA3nhdEmshxayCtAFxA=s64","userId":"07015500522590224135"}},"outputId":"1828104a-e145-4a07-cbc4-3033eced6acc"},"source":["# y_train=mask_train_0.reshape(mask_train_0.shape[0],mask_train_0.shape[1],mask_train_0.shape[2],1)\n","# # mask_dev=mask_dev_0.reshape(mask_dev_0.shape[0],mask_dev_0.shape[1],mask_dev_0.shape[2],1)\n","# y_test=mask_test_0.reshape(mask_test_0.shape[0],mask_test_0.shape[1],mask_test_0.shape[2],1)\n","# print(x_train.shape,y_train.shape, y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(2000, 128, 128, 3) (2000, 128, 128, 1) (600, 128, 128, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PLQ-EqIpVeCs"},"source":["x_train=tf.convert_to_tensor(x_train,tf.float32)\n","y_train=tf.convert_to_tensor(y_train,tf.float32)\n","x_test=tf.convert_to_tensor(x_test,tf.float32)\n","y_test=tf.convert_to_tensor(y_test,tf.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k9lnBcBuVqJb"},"source":["BATCH_SIZE = 32\n","buffer_size = x_train.shape[0]\n","\n","@tf.function\n","def gen_image(image,mask):\n","  # image, mask = brightness(image,mask)\n","  #image, mask = saturation(image,mask)\n","  image, mask = flip(image,mask)\n","  image, mask = rotate_image(image,mask)\n","  image, mask = normalize(image, mask)\n","  return image, mask\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(buffer_size).map(gen_image).batch(BATCH_SIZE)\n","test_dataset = tf.data.Dataset.from_tensor_slices((x_test,y_test)).map(normalize).batch(BATCH_SIZE*2)\n","# val_dataset = tf.data.Dataset.from_tensor_slices((x_val,y_val)).map(normalize).batch(BATCH_SIZE*2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CrTPde-Afn6t"},"source":["# %run UnetModel_TT.ipynb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DZ_x64OujwlU"},"source":["## Models"]},{"cell_type":"code","metadata":{"id":"8-4JsextjrWF"},"source":["from keras.models import Model\n","from keras.layers import Input\n","from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape, Permute\n","from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.merge import Multiply, Concatenate\n","from keras.utils import np_utils\n","import tensorflow as tf\n","from keras.layers import Activation,BatchNormalization,Flatten,Conv2D,Lambda, add, average, Input, Conv2DTranspose, MaxPooling2D, concatenate, Dropout, GlobalAveragePooling2D, Dense\n","\n","from keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Conv2DTranspose, concatenate, Activation, add, UpSampling2D, Lambda, multiply\n","def mvn(tensor):\n","    '''Performs per-channel spatial mean-variance normalization.'''\n","    epsilon = 1e-6\n","    mean = K.mean(tensor, axis=(1,2), keepdims=True)\n","    std = K.std(tensor, axis=(1,2), keepdims=True)\n","    mvn = (tensor - mean) / (std + epsilon)\n","    \n","    return mvn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CTXq9qOKjohr"},"source":["def up_and_concate(down_layer, layer, data_format='channels_last'):\n","    data_format='channels_last'\n","    if data_format == 'channels_first':\n","        in_channel = down_layer.get_shape().as_list()[1]\n","    else:\n","        in_channel = down_layer.get_shape().as_list()[3]\n","\n","    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n","    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n","\n","    if data_format == 'channels_first':\n","        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n","    else:\n","        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n","\n","    concate = my_concat([up, layer])\n","\n","    return concate\n","def attention_up_and_concate(down_layer, layer, data_format='channels_last'):\n","    data_format='channels_last'\n","    if data_format == 'channels_first':\n","        in_channel = down_layer.get_shape().as_list()[1]\n","    else:\n","        in_channel = down_layer.get_shape().as_list()[3]\n","\n","    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n","    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n","\n","    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4, data_format=data_format)\n","\n","    if data_format == 'channels_first':\n","        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n","    else:\n","        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n","\n","    concate = my_concat([up, layer])\n","    return concate\n","def attention_block_2d(x, g, inter_channel, data_format='channels_last'):\n","    data_format='channels_last'\n","    # theta_x(?,g_height,g_width,inter_channel)\n","\n","    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(x)\n","\n","    # phi_g(?,g_height,g_width,inter_channel)\n","\n","    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(g)\n","\n","    # f(?,g_height,g_width,inter_channel)\n","\n","    f = Activation('relu')(add([theta_x, phi_g]))\n","\n","    # psi_f(?,g_height,g_width,1)\n","\n","    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format=data_format)(f)\n","\n","    rate = Activation('sigmoid')(psi_f)\n","\n","    # rate(?,x_height,x_width)\n","\n","    # att_x(?,x_height,x_width,x_channel)\n","\n","    att_x = multiply([x, rate])\n","\n","    return att_x\n","def res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n","\n","              padding='same', data_format='channels_first'):\n","    data_format='channels_last'\n","    if data_format == 'channels_first':\n","        input_n_filters = input_layer.get_shape().as_list()[1]\n","    else:\n","        input_n_filters = input_layer.get_shape().as_list()[3]\n","\n","    layer = input_layer\n","    for i in range(2):\n","        layer = Conv2D(out_n_filters // 4, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n","        if batch_normalization:\n","            layer = BatchNormalization()(layer)\n","        layer = Activation('relu')(layer)\n","        layer = Conv2D(out_n_filters // 4, kernel_size, strides=stride, padding=padding, data_format=data_format)(layer)\n","        layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n","\n","    if out_n_filters != input_n_filters:\n","        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n","            input_layer)\n","    else:\n","        skip_layer = input_layer\n","    out_layer = add([layer, skip_layer])\n","    return out_layer\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QH4ccVxjPmuQ"},"source":["# Modify to work with LMS loss\n","def unet_modified(input_size = (128,128,3),classnum=2,pretrained_weights = None,):\n","    data = Input(shape=input_size, dtype='float', name='data')\n","    mvn0 = Lambda(mvn)(data)\n","    conv1 = Conv2D(64, 3, padding = 'same')(mvn0)\n","    conv1 = Lambda(mvn)(conv1)\n","    conv1 = Activation('relu')(conv1)\n","    conv1 = Conv2D(64, 3,  padding = 'same')(conv1)\n","    conv1 = Lambda(mvn)(conv1)\n","    conv1 = Activation('relu')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","    conv2 = Conv2D(128, 3,  padding = 'same')(pool1)\n","    conv2 = Lambda(mvn)(conv2)\n","    conv2 = Activation('relu')(conv2)\n","    conv2 = Conv2D(128, 3,  padding = 'same')(conv2)\n","    conv2 = Lambda(mvn)(conv2)\n","    conv2 = Activation('relu')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","    conv3 = Conv2D(256, 3,  padding = 'same')(pool2)\n","    conv3 = Lambda(mvn)(conv3)\n","    conv3 = Activation('relu')(conv3)\n","    conv3 = Conv2D(256, 3,  padding = 'same')(conv3)\n","    conv3 = Lambda(mvn)(conv3)\n","    conv3 = Activation('relu')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    \n","    conv4 = Conv2D(512, 3,  padding = 'same')(pool3)\n","    conv4 = Lambda(mvn)(conv4)\n","    conv4 = Activation('relu')(conv4)\n","    conv4 = Conv2D(512, 3,  padding = 'same')(conv4)\n","    conv4 = Lambda(mvn)(conv4)\n","    conv4 = Activation('relu')(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3,  padding = 'same')(pool4)\n","    conv5 = Lambda(mvn)(conv5)\n","    conv5 = Activation('relu')(conv5)\n","    conv5 = Conv2D(1024, 3,  padding = 'same')(conv5)\n","    conv5 = Lambda(mvn)(conv5)\n","    conv5 = Activation('relu')(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    merge6 = attention_up_and_concate(conv5,conv4)\n","    conv6 = Conv2D(512, 3,  padding = 'same')(merge6)\n","    conv6 = Lambda(mvn)(conv6)\n","    conv6 = Activation('relu')(conv6)\n","    conv6 = Conv2D(512, 3,  padding = 'same')(conv6)\n","    conv6 = Lambda(mvn)(conv6)\n","    conv6 = Activation('relu')(conv6)\n","\n","    merge7 = attention_up_and_concate(conv6,conv3)\n","    conv7 = Conv2D(256, 3,  padding = 'same')(merge7)\n","    conv7 = Lambda(mvn)(conv7)\n","    conv7 = Activation('relu')(conv7)\n","    conv7 = Conv2D(256, 3,  padding = 'same')(conv7)\n","    conv7 = Lambda(mvn)(conv7)\n","    conv7 = Activation('relu')(conv7)\n","\n","    merge8 = attention_up_and_concate(conv7,conv2)\n","    conv8 = Conv2D(128, 3,  padding = 'same')(merge8)\n","    conv8 = Lambda(mvn)(conv8)\n","    conv8 = Activation('relu')(conv8)\n","    conv8 = Conv2D(128, 3,  padding = 'same')(conv8)\n","    conv8 = Lambda(mvn)(conv8)\n","    conv8 = Activation('relu')(conv8)\n","\n","    merge9 = attention_up_and_concate(conv8,conv1)\n","    conv9 = Conv2D(64, 3,  padding = 'same')(merge9)\n","    conv9 = Lambda(mvn)(conv9)\n","    conv9 = Activation('relu')(conv9)\n","    conv9 = Conv2D(64, 3,  padding = 'same')(conv9)\n","    conv9 = Lambda(mvn)(conv9)\n","    conv9 = Activation('relu')(conv9)\n","    conv9 = Conv2D(2, 3,  padding = 'same')(conv9)\n","    conv9 = Activation('relu')(conv9)\n","    conv10 = Conv2D(classnum, 1, activation = 'softmax')(conv9) #modify this\n","     # If Dice loss: conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","    model = Model(data, conv10)\n","\n","    # model.compile(optimizer = SGD(lr = 0.01,momentum=0.9), loss = focal_tversky, metrics = ['accuracy',dice_coef])\n","    \n","    #model.summary()\n","\n","    if(pretrained_weights):\n","    \tmodel.load_weights(pretrained_weights)\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HInqL8dvR5bj"},"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.models import *\n","from tensorflow.keras.layers import *\n","import keras.backend as K\n","class Swish(tf.keras.layers.Layer):\n","    def __init__(self, name=None, **kwargs):\n","        super().__init__(name=name, **kwargs)\n","\n","    def call(self, inputs, **kwargs):\n","        return tf.nn.swish(inputs)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config['name'] = self.name\n","        return config\n","def squeeze_excite_block(reduce_ratio=0.25,name_block=None):\n","  def call(inputs):\n","    filters = inputs.shape[-1]\n","    num_reduced_filters= max(1, int(filters * reduce_ratio))\n","    se = Lambda(lambda a: K.mean(a, axis=[1,2], keepdims=True))(inputs)\n","\n","    se = Conv2D(\n","            num_reduced_filters,\n","            kernel_size=[1, 1],\n","            strides=[1, 1],\n","            kernel_initializer='he_normal',\n","            padding='same',\n","            use_bias=True\n","        )(se)\n","    se = Swish()(se)\n","    se = Conv2D(\n","            filters,\n","            kernel_size=[1, 1],\n","            strides=[1, 1],\n","            kernel_initializer='he_normal',\n","            padding='same',\n","            use_bias=True\n","        )(se)\n","    se = Activation('sigmoid')(se)\n","    if name_block is not None:\n","      out = Multiply(name=name_block)([se, inputs])\n","    else : \n","      out = Multiply()([se, inputs])\n","    return out\n","  return call\n","\n","def conv_block(filters,kernel_size = (3,3), dilation = 1,block_name=None):\n","  def call(inputs):\n","    x = inputs\n","\n","    x = Conv2D(filters, kernel_size, padding=\"same\",dilation_rate =dilation ,use_bias=False,kernel_initializer='he_normal')(x)\n","    x = BatchNormalization()(x)\n","    x = Swish()(x)\n","\n","    x = Conv2D(filters, kernel_size, padding=\"same\",dilation_rate =dilation, use_bias=False,kernel_initializer='he_normal')(x)\n","    x = BatchNormalization()(x)\n","    x = Swish()(x)\n","\n","    x = squeeze_excite_block(name_block=block_name)(x)\n","\n","    return x\n","  return call\n","\n","\n","def decoder_block(n_filter,skip=None):\n","  def call(inputs):\n","    x= Conv2DTranspose(n_filter, (2,2), strides=(2, 2), padding='same',kernel_initializer = 'he_normal')(inputs)\n","    out = x\n","    if skip is not None :\n","      attention = conv_block(n_filter)(skip)\n","      out = Concatenate()([x,attention])\n","    out = conv_block(n_filter)(out)\n","\n","    return out\n","  return call\n","def dow_block(kernel_size=(2,2),stride=(2,2)):\n","  def call(inputs):\n","    out = MaxPooling2D(kernel_size, strides=stride)(inputs)\n","    return out\n","  return call\n","\n","def encoderSegnet(input_s=(128,128,1)):\n","  down_block = dow_block()\n","  inp= Input(shape=input_s)\n","  o = inp\n","  nums_filter=[64,128,256,512,512]\n","  count=0\n","  for f in nums_filter[:-1]:\n","    count+=1\n","    o = conv_block(f,block_name='output_block_'+str(count))(o)\n","    o = down_block(o)\n","\n","  o = conv_block(nums_filter[-1],block_name='output_block_'+str(count+1))(o)\n","  #o = Dropout(0.5)(o)\n","  return Model(inp,o)  \n","list_skip = [\"output_block_4\", \"output_block_3\", \"output_block_2\", \"output_block_1\"]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LiTvE_dXPwTx"},"source":["def u_net1(input_size=(192,256,3), out_channels=3):\n","  # encoder = encoderSegnet(input_s = input_size)\n","  data = Input(shape=input_size, dtype='float', name='data')\n","  mvn0 = Lambda(mvn)(data)\n","  conv1 = Conv2D(64, 3, padding = 'same')(mvn0)\n","  conv1 = Lambda(mvn)(conv1)\n","  conv1 = Activation('relu')(conv1)\n","  conv1 = Conv2D(64, 3,  padding = 'same')(conv1)\n","  conv1 = Lambda(mvn)(conv1)\n","  conv1 = Activation('relu')(conv1)\n","  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","  conv2 = Conv2D(128, 3,  padding = 'same')(pool1)\n","  conv2 = Lambda(mvn)(conv2)\n","  conv2 = Activation('relu')(conv2)\n","  conv2 = Conv2D(128, 3,  padding = 'same')(conv2)\n","  conv2 = Lambda(mvn)(conv2)\n","  conv2 = Activation('relu')(conv2)\n","  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","  conv3 = Conv2D(256, 3,  padding = 'same')(pool2)\n","  conv3 = Lambda(mvn)(conv3)\n","  conv3 = Activation('relu')(conv3)\n","  conv3 = Conv2D(256, 3,  padding = 'same')(conv3)\n","  conv3 = Lambda(mvn)(conv3)\n","  conv3 = Activation('relu')(conv3)\n","  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    \n","  conv4 = Conv2D(512, 3,  padding = 'same')(pool3)\n","  conv4 = Lambda(mvn)(conv4)\n","  conv4 = Activation('relu')(conv4)\n","  conv4 = Conv2D(512, 3,  padding = 'same')(conv4)\n","  conv4 = Lambda(mvn)(conv4)\n","  conv4 = Activation('relu')(conv4)\n","  drop4 = Dropout(0.5)(conv4)\n","  pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","  conv5 = Conv2D(1024, 3,  padding = 'same')(pool4)\n","  conv5 = Lambda(mvn)(conv5)\n","  conv5 = Activation('relu')(conv5)\n","  conv5 = Conv2D(1024, 3,  padding = 'same')(conv5)\n","  conv5 = Lambda(mvn)(conv5)\n","  conv5 = Activation('relu')(conv5)\n","  drop5 = Dropout(0.5)(conv5)\n","\n","  merge6 = attention_up_and_concate(conv5,conv4)\n","  conv6 = Conv2D(512, 3,  padding = 'same')(merge6)\n","  conv6 = Lambda(mvn)(conv6)\n","  conv6 = Activation('relu')(conv6)\n","  conv6 = Conv2D(512, 3,  padding = 'same')(conv6)\n","  conv6 = Lambda(mvn)(conv6)\n","  conv6 = Activation('relu')(conv6)\n","\n","  merge7 = attention_up_and_concate(conv6,conv3)\n","  conv7 = Conv2D(256, 3,  padding = 'same')(merge7)\n","  conv7 = Lambda(mvn)(conv7)\n","  conv7 = Activation('relu')(conv7)\n","  conv7 = Conv2D(256, 3,  padding = 'same')(conv7)\n","  conv7 = Lambda(mvn)(conv7)\n","  conv7 = Activation('relu')(conv7)\n","\n","  merge8 = attention_up_and_concate(conv7,conv2)\n","  conv8 = Conv2D(128, 3,  padding = 'same')(merge8)\n","  conv8 = Lambda(mvn)(conv8)\n","  conv8 = Activation('relu')(conv8)\n","  conv8 = Conv2D(128, 3,  padding = 'same')(conv8)\n","  conv8 = Lambda(mvn)(conv8)\n","  conv8 = Activation('relu')(conv8)\n","\n","  merge9 = attention_up_and_concate(conv8,conv1)\n","  conv9 = Conv2D(64, 3,  padding = 'same')(merge9)\n","  conv9 = Lambda(mvn)(conv9)\n","  conv9 = Activation('relu')(conv9)\n","  conv9 = Conv2D(64, 3,  padding = 'same')(conv9)\n","  conv9 = Lambda(mvn)(conv9)\n","  conv9 = Activation('relu')(conv9)\n","  conv9 = Conv2D(2, 3,  padding = 'same')(conv9)\n","  conv9 = Activation('relu')(conv9)\n","  conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","  # model = Model(data, conv10)\n","\n","    # model.compile(optimizer = SGD(lr = 0.01,momentum=0.9), loss = focal_tversky, metrics = ['accuracy',dice_coef])\n","    \n","    #model.summary()\n","\n","  # o = Conv2D(out_channels,(3, 3), padding='same', kernel_initializer='he_normal')(conv10)\n","  # yn = Activation('softmax')(o[...,:-1])\n","  # bn = o[...,-1:]\n","  # output = Concatenate()([yn,bn])\n","  # if out_channels > 1 : \n","  #   output = Activation('softmax', name = 'softmax')(o)\n","  # else :\n","  #   output = Activation('sigmoid', name = 'sigmoid')(o)\n","  return Model(data,conv10) \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AROZhkRBPdrl"},"source":["## Not tested yet"]},{"cell_type":"code","metadata":{"id":"sPH6aKtgkz1Z"},"source":["#Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\n","def r2unet(input_size = (192,288,3),classnum=2,pretrained_weights = None,):\n","    data_format='channels_last'\n","    data = Input(shape=input_size, dtype='float', name='data')\n","    x = data\n","    depth = 4\n","    features = 64\n","    skips = []\n","    for i in range(depth):\n","        x = rec_res_block(x, features, data_format=data_format)\n","        skips.append(x)\n","        x = MaxPooling2D((2, 2), data_format=data_format)(x)\n","\n","        features = features * 2\n","\n","    x = rec_res_block(x, features, data_format=data_format)\n","\n","    for i in reversed(range(depth)):\n","        features = features // 2\n","        x = up_and_concate(x, skips[i], data_format=data_format)\n","        x = rec_res_block(x, features, data_format=data_format)\n","\n","    conv6 = Conv2D(classnum, (1, 1), padding='same', data_format=data_format)(x)\n","    conv7 = Activation('sigmoid')(conv6)\n","    model = Model(data,conv7)\n","    # model = Model(inputs=inputs, outputs=conv7)\n","\n","    # conv6 =Conv2D(classnum, (1, 1), padding='same', data_format=data_format)(x)\n","    # conv7=Activation('softmax')(conv6)\n","    # model = Model(data,conv7)\n","\n","\n","    #model.compile(optimizer=Adam(lr=1e-6), loss=[dice_coef_loss], metrics=['accuracy', dice_coef])\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7BYXr3lIna1H"},"source":["#Attention R2U-Net\n","def att_r2unet(input_size = (192,288,3), out_channels=2):\n","    data_format='channels_last'\n","    data = Input(shape=input_size, name='data')\n","    x = data\n","    depth = 4\n","    features = 64\n","    skips = []\n","    for i in range(depth):\n","        x = rec_res_block(x, features, data_format=data_format)\n","        skips.append(x)\n","        x = MaxPooling2D((2, 2), data_format=data_format)(x)\n","\n","        features = features * 2\n","\n","    x = rec_res_block(x, features, data_format=data_format)\n","\n","    for i in reversed(range(depth)):\n","        features = features // 2\n","        x = attention_up_and_concate(x, skips[i], data_format=data_format)\n","        x = rec_res_block(x, features, data_format=data_format)\n","\n","    # conv6 = Conv2D(out_channels, (1, 1), padding='same', data_format=data_format)(x)\n","    # conv6 = Activation('softmax')(conv6)\n","    # model = Model(data, conv6)\n","    conv6 =Conv2D(out_channels, (1, 1), padding='same', data_format=data_format)(x)\n","    conv7=Activation('softmax')(conv6)\n","    model = Model(data,conv7)\n","\n","\n","    #model.compile(optimizer=Adam(lr=1e-6), loss=[dice_coef_loss], metrics=['accuracy', dice_coef])\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sHQGURfkKvj4"},"source":["# S = att_unet(input_size = (192,288,3),classnum=2)# not tested yet\n","# S = att_r2unet(input_size = (128,128,3), out_channels=2)# not tested yet\n","# S = r2unet(input_size = (192,288,3),classnum=2)\n","S = r2unet(input_size = (128,128,3),classnum=2)\n","nhat = Mumford_Unet_vs2(S)\n","nhat.learning_rate = 0.001\n","nhat.trainData = train_dataset\n","nhat.testData = test_dataset\n","nhat.optimizer_fc(op_type = \"nadam\", op_param=nhat.learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uZ84My08PiDK"},"source":["## Train by LMS loss"]},{"cell_type":"code","metadata":{"id":"GM_w8k2MQlB4"},"source":["class MSLoss_vs2():\n","  def levelsetLoss(self,target, output):\n","    loss = 0.0\n","    for ich in range(target.shape[3]):\n","        target_ = target[...,ich:ich+1]    \n","        pcentroid = tf.reduce_sum(target_ * output, (1,2),keepdims=True)/tf.reduce_sum(output, (1,2),keepdims = True)   \n","        plevel = target_ - pcentroid\n","        pLoss = plevel * plevel * output\n","        loss += tf.reduce_sum(pLoss)\n","    return loss\n","      \n","  def activeContourLoss(self,y_true,y_pred,outDim =2,smooth=0.001):     \n","    yTrueOnehot = tf.one_hot(tf.squeeze(tf.cast(y_true,tf.uint8),axis=-1), depth = outDim)\n","    loss =  y_pred * (1-yTrueOnehot) + (1-y_pred)*yTrueOnehot\n","    return tf.reduce_mean(loss)\n","    #this is Luac:\n","    # loss =  - tf.cast(tf.math.log(1-y_pred+smooth),tf.float32) * (1-yTrueOnehot ) - tf.cast(tf.math.log(y_pred+smooth),tf.float32)*yTrueOnehot\n","    # return tf.reduce_mean(loss)\n","                    \n","  def gradientLoss(self,input,penalty = \"l1\"):\n","\n","    dH = tf.math.abs(input[:, 1:, :, :] - input[:, :-1, :, :])\n","    dW = tf.math.abs(input[:, :, 1:, :] - input[:, :, :-1, :])\n","    if penalty == \"l2\":\n","        dH = dH * dH\n","        dW = dW * dW\n","\n","    loss =  tf.reduce_sum(dH) +  tf.reduce_sum(dW)\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HqtJh9OfVvl_"},"source":["class Mumford_Unet_vs2(MSLoss_vs2):\n","  def __init__(self,model):\n","    super().__init__()\n","    self.model = model\n","    self.optimizer = None\n","    self.trainData = None\n","    self.testData = None\n","    self.batch_size = BATCH_SIZE\n","    temp = x_train.shape[0] // self.batch_size\n","    self.train_step = temp + 1 if x_train.shape[0] % self.batch_size != 0 else temp\n","    self.learning_rate = 0.001\n","\n","  def optimizer_fc(self,op_type = \"adam\", op_param = 0.005):\n","    if op_type == 'adam':\n","      self.optimizer =  tf.keras.optimizers.Adam(op_param)\n","    elif op_type == \"nadam\":\n","      self.optimizer =  tf.keras.optimizers.Nadam(op_param)\n","\n","  def loss(self, image, output, trueLabel, alpha = 1e-3, beta = 0.001):\n","    print('\\ractive loss: ',self.activeContourLoss(trueLabel, output),' leverset loss: ', self.levelsetLoss(image,output),'gradient loss: ', self.gradientLoss(output), end=\"\")\n","    return alpha * ( self.levelsetLoss(image,output) + beta * self.gradientLoss(output)) + self.activeContourLoss(trueLabel, output)\n","    # return self.activeContourLoss(trueLabel, output)\n","\n","  def metrics(self,y_true,y_pred):\n","    output_standard = tf.expand_dims(tf.argmax(y_pred,axis=-1),axis = -1)\n","    output_standard = tf.cast(output_standard,tf.float32)\n","    dice = dice_coef(y_true, output_standard)\n","    jaccard = jaccard_coef(y_true, output_standard)\n","    return dice, jaccard\n","\n","  def evaluateTest(self,testDataset):\n","    test_dices =  []\n","    test_jaccards =  []\n","    for xBatchTest, yBatchTest in testDataset:\n","      yPredBatchTest = self.model(xBatchTest, training =False)\n","      diceTest, jaccardTest =  self.metrics(yBatchTest, yPredBatchTest)\n","      test_dices.append(diceTest)\n","      test_jaccards.append(jaccardTest)\n","    return np.mean(test_dices), np.mean(test_jaccards)\n","\n","  def epoch_training(self,model,optimizer, trainDataset, testDataset, mb, stepTrain, alpha_loss, beta_loss):\n","    train_losses = []\n","    train_dices =  []\n","    train_jaccards =  []\n","\n","    trainDataset = iter(trainDataset)  \n","    for _ in progress_bar(range(stepTrain),parent = mb):   \n","      with tf.GradientTape() as tape:\n","        image, y_true = next(trainDataset)\n","        y_pred = self.model(image, training = True)\n","        total_loss  =  self.loss(image, y_pred, y_true, alpha_loss, beta_loss)\n","\n","      \n","      grad  = tape.gradient(total_loss, self.model.trainable_variables)\n","      optimizer.apply_gradients(zip(grad,self.model.trainable_variables))\n","\n","      diceTrain, jaccardTrain =  self.metrics(y_true, y_pred)\n","\n","      mb.child.comment = 'Train loss {:.4f}'.format(total_loss)\n","\n","      train_losses.append(total_loss)\n","      train_dices.append(diceTrain)\n","      train_jaccards.append(jaccardTrain)\n","\n","    trainLossMean = np.mean(train_losses)\n","    trainDiceMean = np.mean(train_dices)\n","    trainJaccardMean = np.mean(train_jaccards)\n","\n","    testDiceMean, testJaccardMean = self.evaluateTest(testDataset)\n","\n","    return trainLossMean, trainDiceMean, trainJaccardMean, testDiceMean, testJaccardMean\n","\n","\n","  def train(self,num_epoch, reduceLrEpoch=10 , earlyStoping=22, minLr=1e-5, alpha_loss= 1e-6, beta_loss = 1,checkpoint_prefix = \"m\"):\n","    mb = master_bar(range(num_epoch))\n","    epochs_list = []\n","    history = dict()\n","    training_losses = []\n","    trainDice_list = []\n","    trainJaccard_list = []\n","    testDice_list = []\n","    testJaccard_list = []\n","    # learningRate_list = []\n","    best_score  = 0\n","    count = 0\n","    for epoch in mb:\n","      count += 1\n","      epochs_list.append(epoch+1)\n","\n","      trainLoss, trainDice, trainJaccard, testDice, testJaccard  \\\n","      = self.epoch_training(self.model, self.optimizer, self.trainData, self.testData, mb, self.train_step, alpha_loss, beta_loss)\n","\n","      mb.write('Finish train epoch {} with loss {:.4f} trainDice: {:.4f}, trainJaccard: {:.4f}, testDice: {:.4f},\\\n","       testJaccard: {:.4f}'.format(epoch+1, trainLoss, trainDice, trainJaccard, testDice, testJaccard))\n","\n","      training_losses.append(trainLoss)\n","      trainDice_list.append(trainDice)\n","      trainJaccard_list.append(trainJaccard)\n","      testDice_list.append(testDice)\n","      testJaccard_list.append(testJaccard)\n","      # learningRate_list.append(self.learning_rate)\n","\n","      if count % reduceLrEpoch ==0 :\n","        self.learning_rate = self.learning_rate * 0.5\n","        if self.learning_rate < minLr:\n","          self.learning_rate = minLr\n","        print('learning rate is set to : ',self.learning_rate)\n","        self.optimizer.learning_rate.assign(self.learning_rate )\n","    \n","      mb.update_graph([[epochs_list, training_losses]], [0,num_epoch], [0,0.1])\n","      if count == earlyStoping :\n","        break\n","      ### Check point here ###\n","      ### Check point follow testDice ###\n","      if best_score < testDice:\n","          count = 0\n","          mb.write(\">>> Improved Dice-score from {:.4f} to {:.4f}\".format(best_score, testDice))\n","          best_score = testDice\n","          self.model.save_weights(checkpoint_prefix.format(score=best_score))\n","    history['epoch'] = epochs_list\n","    history['train_loss'] = training_losses\n","    history['train_dice'] = trainDice_list\n","    history['train_jaccard'] = trainJaccard_list\n","    history['test_dice'] = testDice_list\n","    history['test_jaccard'] = testJaccard_list\n","    # history['lr'] = learningRate_list\n","    return history "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q8uLHg6aP3XX"},"source":["S = unet_modified((128,128,3),classnum=2)\n","nhat = Mumford_Unet_vs2(S)\n","nhat.learning_rate = 0.001\n","nhat.trainData = train_dataset\n","nhat.testData = test_dataset\n","nhat.optimizer_fc(op_type = \"nadam\", op_param=nhat.learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n61fPk5glGik","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"67704e73-0ee4-456b-dd01-28e9bbe50d12"},"source":["import shutil\n","file_name = 'weight_LMS_loss_unet'\n","if os.path.exists(file_name):\n","  shutil.rmtree(file_name)  \n","os.mkdir(file_name)\n","history = nhat.train(70,alpha_loss=1e-6,beta_loss=1e-2,checkpoint_prefix=\"./weight_LMS_loss_unet/ckpt_{score:.4f}.h5\")\n","sio.savemat('isic17_LMS_Unet.mat',history)\n","nhat.evaluateTest(test_dataset)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='51' class='' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      72.86% [51/70 1:05:15<24:18]\n","    </div>\n","    \n","Finish train epoch 1 with loss 0.1426 trainDice: 0.6096, trainJaccard: 0.5324, testDice: 0.6985,       testJaccard: 0.5708<p>>>> Improved Dice-score from 0.0000 to 0.6985<p>Finish train epoch 2 with loss 0.1214 trainDice: 0.8207, trainJaccard: 0.7293, testDice: 0.7338,       testJaccard: 0.6252<p>>>> Improved Dice-score from 0.6985 to 0.7338<p>Finish train epoch 3 with loss 0.1148 trainDice: 0.8350, trainJaccard: 0.7478, testDice: 0.7864,       testJaccard: 0.6885<p>>>> Improved Dice-score from 0.7338 to 0.7864<p>Finish train epoch 4 with loss 0.1067 trainDice: 0.8526, trainJaccard: 0.7706, testDice: 0.8196,       testJaccard: 0.7273<p>>>> Improved Dice-score from 0.7864 to 0.8196<p>Finish train epoch 5 with loss 0.0999 trainDice: 0.8621, trainJaccard: 0.7824, testDice: 0.8262,       testJaccard: 0.7340<p>>>> Improved Dice-score from 0.8196 to 0.8262<p>Finish train epoch 6 with loss 0.0968 trainDice: 0.8609, trainJaccard: 0.7807, testDice: 0.8208,       testJaccard: 0.7293<p>Finish train epoch 7 with loss 0.0921 trainDice: 0.8615, trainJaccard: 0.7822, testDice: 0.8089,       testJaccard: 0.7164<p>Finish train epoch 8 with loss 0.0873 trainDice: 0.8700, trainJaccard: 0.7938, testDice: 0.7257,       testJaccard: 0.6158<p>Finish train epoch 9 with loss 0.0810 trainDice: 0.8773, trainJaccard: 0.8024, testDice: 0.7684,       testJaccard: 0.6741<p>Finish train epoch 10 with loss 0.0796 trainDice: 0.8709, trainJaccard: 0.7959, testDice: 0.8258,       testJaccard: 0.7366<p>Finish train epoch 11 with loss 0.0725 trainDice: 0.8845, trainJaccard: 0.8116, testDice: 0.8102,       testJaccard: 0.7157<p>Finish train epoch 12 with loss 0.0698 trainDice: 0.8859, trainJaccard: 0.8146, testDice: 0.7864,       testJaccard: 0.6927<p>Finish train epoch 13 with loss 0.0681 trainDice: 0.8838, trainJaccard: 0.8123, testDice: 0.8179,       testJaccard: 0.7287<p>Finish train epoch 14 with loss 0.0644 trainDice: 0.8893, trainJaccard: 0.8190, testDice: 0.8307,       testJaccard: 0.7412<p>>>> Improved Dice-score from 0.8262 to 0.8307<p>Finish train epoch 15 with loss 0.0647 trainDice: 0.8825, trainJaccard: 0.8104, testDice: 0.8332,       testJaccard: 0.7445<p>>>> Improved Dice-score from 0.8307 to 0.8332<p>Finish train epoch 16 with loss 0.0596 trainDice: 0.8901, trainJaccard: 0.8200, testDice: 0.8141,       testJaccard: 0.7214<p>Finish train epoch 17 with loss 0.0593 trainDice: 0.8856, trainJaccard: 0.8145, testDice: 0.8054,       testJaccard: 0.7115<p>Finish train epoch 18 with loss 0.0574 trainDice: 0.8875, trainJaccard: 0.8161, testDice: 0.8406,       testJaccard: 0.7530<p>>>> Improved Dice-score from 0.8332 to 0.8406<p>Finish train epoch 19 with loss 0.0545 trainDice: 0.8917, trainJaccard: 0.8225, testDice: 0.8084,       testJaccard: 0.7082<p>Finish train epoch 20 with loss 0.0552 trainDice: 0.8875, trainJaccard: 0.8164, testDice: 0.8349,       testJaccard: 0.7467<p>Finish train epoch 21 with loss 0.0521 trainDice: 0.8924, trainJaccard: 0.8231, testDice: 0.8292,       testJaccard: 0.7401<p>Finish train epoch 22 with loss 0.0489 trainDice: 0.8994, trainJaccard: 0.8325, testDice: 0.8423,       testJaccard: 0.7558<p>>>> Improved Dice-score from 0.8406 to 0.8423<p>Finish train epoch 23 with loss 0.0481 trainDice: 0.9001, trainJaccard: 0.8332, testDice: 0.8343,       testJaccard: 0.7481<p>Finish train epoch 24 with loss 0.0576 trainDice: 0.8705, trainJaccard: 0.7946, testDice: 0.7802,       testJaccard: 0.6722<p>Finish train epoch 25 with loss 0.0526 trainDice: 0.8792, trainJaccard: 0.8038, testDice: 0.8282,       testJaccard: 0.7407<p>Finish train epoch 26 with loss 0.0477 trainDice: 0.8936, trainJaccard: 0.8245, testDice: 0.8339,       testJaccard: 0.7475<p>Finish train epoch 27 with loss 0.0457 trainDice: 0.8965, trainJaccard: 0.8286, testDice: 0.8212,       testJaccard: 0.7301<p>Finish train epoch 28 with loss 0.0445 trainDice: 0.8983, trainJaccard: 0.8307, testDice: 0.8249,       testJaccard: 0.7363<p>Finish train epoch 29 with loss 0.0464 trainDice: 0.8909, trainJaccard: 0.8213, testDice: 0.8372,       testJaccard: 0.7492<p>Finish train epoch 30 with loss 0.0430 trainDice: 0.8999, trainJaccard: 0.8334, testDice: 0.7945,       testJaccard: 0.7029<p>Finish train epoch 31 with loss 0.0421 trainDice: 0.9003, trainJaccard: 0.8332, testDice: 0.8297,       testJaccard: 0.7424<p>Finish train epoch 32 with loss 0.0400 trainDice: 0.9016, trainJaccard: 0.8361, testDice: 0.8384,       testJaccard: 0.7527<p>Finish train epoch 33 with loss 0.0392 trainDice: 0.9057, trainJaccard: 0.8416, testDice: 0.8395,       testJaccard: 0.7530<p>Finish train epoch 34 with loss 0.0380 trainDice: 0.9090, trainJaccard: 0.8456, testDice: 0.8466,       testJaccard: 0.7625<p>>>> Improved Dice-score from 0.8423 to 0.8466<p>Finish train epoch 35 with loss 0.0376 trainDice: 0.9081, trainJaccard: 0.8446, testDice: 0.8318,       testJaccard: 0.7433<p>Finish train epoch 36 with loss 0.0372 trainDice: 0.9101, trainJaccard: 0.8476, testDice: 0.8403,       testJaccard: 0.7549<p>Finish train epoch 37 with loss 0.0365 trainDice: 0.9108, trainJaccard: 0.8486, testDice: 0.8378,       testJaccard: 0.7523<p>Finish train epoch 38 with loss 0.0368 trainDice: 0.9095, trainJaccard: 0.8467, testDice: 0.8328,       testJaccard: 0.7458<p>Finish train epoch 39 with loss 0.0363 trainDice: 0.9103, trainJaccard: 0.8480, testDice: 0.8221,       testJaccard: 0.7301<p>Finish train epoch 40 with loss 0.0359 trainDice: 0.9100, trainJaccard: 0.8470, testDice: 0.8308,       testJaccard: 0.7432<p>Finish train epoch 41 with loss 0.0356 trainDice: 0.9113, trainJaccard: 0.8494, testDice: 0.8175,       testJaccard: 0.7281<p>Finish train epoch 42 with loss 0.0350 trainDice: 0.9118, trainJaccard: 0.8496, testDice: 0.8451,       testJaccard: 0.7616<p>Finish train epoch 43 with loss 0.0348 trainDice: 0.9094, trainJaccard: 0.8470, testDice: 0.8279,       testJaccard: 0.7384<p>Finish train epoch 44 with loss 0.0343 trainDice: 0.9119, trainJaccard: 0.8500, testDice: 0.8098,       testJaccard: 0.7151<p>Finish train epoch 45 with loss 0.0339 trainDice: 0.9142, trainJaccard: 0.8534, testDice: 0.8409,       testJaccard: 0.7548<p>Finish train epoch 46 with loss 0.0330 trainDice: 0.9154, trainJaccard: 0.8551, testDice: 0.8389,       testJaccard: 0.7524<p>Finish train epoch 47 with loss 0.0327 trainDice: 0.9160, trainJaccard: 0.8560, testDice: 0.8431,       testJaccard: 0.7587<p>Finish train epoch 48 with loss 0.0335 trainDice: 0.9151, trainJaccard: 0.8549, testDice: 0.8417,       testJaccard: 0.7553<p>Finish train epoch 49 with loss 0.0327 trainDice: 0.9156, trainJaccard: 0.8553, testDice: 0.8447,       testJaccard: 0.7611<p>Finish train epoch 50 with loss 0.0328 trainDice: 0.9148, trainJaccard: 0.8542, testDice: 0.8284,       testJaccard: 0.7402<p>Finish train epoch 51 with loss 0.0320 trainDice: 0.9159, trainJaccard: 0.8559, testDice: 0.8422,       testJaccard: 0.7567<p>\n","\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='63' class='' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [63/63 00:52<00:00 Train loss 0.0264]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["active loss:  tf.Tensor(0.20847811, shape=(), dtype=float32)  leverset loss:  tf.Tensor(0.8824639, shape=(), dtype=float32) gradient loss:  tf.Tensor(7351.7295, shape=(), dtype=float32)"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["active loss:  tf.Tensor(0.044448107, shape=(), dtype=float32)  leverset loss:  tf.Tensor(0.6633963, shape=(), dtype=float32) gradient loss:  tf.Tensor(6827.7246, shape=(), dtype=float32)learning rate is set to :  0.0005\n","active loss:  tf.Tensor(0.028703975, shape=(), dtype=float32)  leverset loss:  tf.Tensor(0.441951, shape=(), dtype=float32) gradient loss:  tf.Tensor(6594.8237, shape=(), dtype=float32)learning rate is set to :  0.00025\n","active loss:  tf.Tensor(0.026260927, shape=(), dtype=float32)  leverset loss:  tf.Tensor(0.6209923, shape=(), dtype=float32) gradient loss:  tf.Tensor(8930.648, shape=(), dtype=float32)"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ffjKAad1Q_HY"},"source":["# nhat.model.load_weights('weight_isic17_MS_ckpt_0.8463.h5')\n","x_test_org= np.load(data_folder+'x_test2017_128.npy')\n","y_test_org= np.load(data_folder+'y_test2017_128.npy')\n","nhat.evaluateTest(test_dataset)\n","model1=nhat.model\n","y_pred_all=model1.predict(x_test_org)\n","import scipy.io as sio\n","sio.savemat('Result_isic17_LMS_Unet.mat'\n","            , {'history': history, 'y_pred_all': y_pred_all, 'x_test': x_test_org, 'y_test': y_test_org})\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PvJ8ziG1RAqP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nGuajDXcQ3EV"},"source":["## Dice loss"]},{"cell_type":"code","metadata":{"id":"84yuZyHcSLUo"},"source":["import keras.backend as K\n","\n","def dice_coef(y_true, y_pred, smooth=1e-10):\n","    '''Average dice coefficient per batch.'''\n","    axes = (1,2,3)\n","    intersection = K.sum(y_true * y_pred, axis=axes)\n","    summation = K.sum(y_true + y_pred, axis=axes)\n","    return K.mean((2.0 * intersection + smooth) / (summation + smooth), axis=0)\n","\n","def jaccard_coef(y_true, y_pred, smooth=1e-10):\n","    '''Average jaccard coefficient per batch.'''\n","    axes = (1,2,3)\n","    intersection = K.sum(y_true * y_pred, axis=axes)\n","    union = K.sum(y_true + y_pred, axis=axes) - intersection\n","    return K.mean( (intersection + smooth) / (union + smooth), axis=0)\n","def dice_coef_loss(y_true, y_pred):\n","    return 1.0 - dice_coef(y_true, y_pred, 0.0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"afG6C0XyRZya"},"source":["S1=u_net1((128,128,3),out_channels=2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1F99-zCFSQj_"},"source":["S1.compile(loss = dice_coef_loss,optimizer=tf.keras.optimizers.Nadam(0.001),metrics=[dice_coef, jaccard_coef])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gH9GAEppfgO3"},"source":["import shutil\n","file_name = 'weight_Dice_loss_unet'\n","if os.path.exists(file_name):\n","  shutil.rmtree(file_name)  \n","os.mkdir(file_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aGykGhvuRcC_"},"source":["from keras.callbacks import ModelCheckpoint,EarlyStopping\n","mcp = ModelCheckpoint(\"./weight_Dice_loss_unet/weight_{val_dice_coef:.4f}.h5\",mode='max',monitor='val_dice_coef',verbose=1,save_best_only=True,save_weights_only=True)\n","earlystop= EarlyStopping(monitor='val_dice_coef',patience=30,mode='max',verbose=1)\n","rlr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, mode='max', patience=50, min_lr=1e-6, verbose=1)\n","history = S1.fit(train_dataset,validation_data=test_dataset,\n","\t    epochs=300,callbacks=[earlystop,mcp],verbose=1)\n","\n","sio.savemat('./weight_Dice_loss_unet/historyISIC_UnetBase.mat',history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_qV7cuPw6hf6"},"source":["# # nhat.model.load_weights('weight_NewLoss_r2unet/ckpt_.h5')\n","\n","# nhat.evaluateTest(test_dataset)\n","# model1=nhat.model\n","# y_pred_all=model1.predict(x_test)\n","# import scipy.io as sio\n","# sio.savemat('Result_isic17_newLoss_r2unet.mat'\n","#             , {'history': history, 'y_pred_all': y_pred_all, 'x_test': x_test, 'y_test': y_test})\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ggufsOvKyRR"},"source":["# history = nhat.train(70,alpha_loss=1e-6,beta_loss=1e-2,checkpoint_prefix=\"/content/drive/MyDrive/Pix2Pix-for-Semantic-Segmentation-of-Satellite-Images/_checkpoint/ckpt_{score:.4f}.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dAaJBPn5q8K3"},"source":["# sio.savemat('/content/drive/MyDrive/Pix2Pix-for-Semantic-Segmentation-of-Satellite-Images/_checkpoint/history.mat',history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HoH74U16K0Ic"},"source":["# nhat.model.load_weights('/content/drive/MyDrive/LMSLoss/weightISIC_MS/ckpt_0.8829.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sYlhJsqrbnqa"},"source":["# nhat.evaluateTest(test_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0wBJPJ7WUYJd"},"source":["# for i in range(x_test.shape[0]):\n","#   y_pred = nhat.model(normalize(x_test[i:i+1],y_test[i:i+1]))\n","#   y_predShow = np.argmax(y_pred,axis = -1)\n","#   plt.figure(i+1)\n","#   plt.subplot(131),plt.imshow(x_test[i]),plt.title('image')\n","#   plt.subplot(132),plt.imshow(y_predShow[0],cmap ='gray'),plt.title('predict')\n","#   plt.subplot(133),plt.imshow(y_test[i,...,0],cmap='gray'),plt.title('groundtruth')"],"execution_count":null,"outputs":[]}]}